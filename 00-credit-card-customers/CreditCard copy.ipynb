{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e818d7d",
   "metadata": {},
   "source": [
    "<!-- Google Fonts -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #fff; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 10px; \n",
    "        font-size: 36px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        üíµ Credit Card Customers ‚öñÔ∏è\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa1244",
   "metadata": {},
   "source": [
    "# üìÇ Overview\n",
    "\n",
    "**Background**\n",
    "\n",
    "This dataset contains **credit card customer data** from a fictional bank. It simulates real-world customer behavior with features related to demographics, credit usage, and account activity.\n",
    "\n",
    "This binary classification problem aims to **predict whether a customer will churn** based on their profile and activity.\n",
    "\n",
    "**Goal of the Project**\n",
    "\n",
    "Build a machine learning model to **predict whether a customer will leave the credit card service** (`Attrition_Flag`: Attrited/Existing).\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "| Feature Name               | Description                                           |\n",
    "| -------------------------- | ----------------------------------------------------- |\n",
    "| `CLIENTNUM`                | Unique customer ID (not used for modeling)            |\n",
    "| `Attrition_Flag`           | Churn status: üü¢ Existing or üî¥ Attrited             |\n",
    "| `Customer_Age`             | Age of the customer                                   |\n",
    "| `Gender`                   | Customer gender                                       |\n",
    "| `Dependent_count`          | Number of dependents                                  |\n",
    "| `Education_Level`          | Education level (High School, Graduate, etc.)         |\n",
    "| `Marital_Status`           | Marital status (Married, Single, etc.)                |\n",
    "| `Income_Category`          | Income bracket (Less than \\$40K, \\$40K - \\$60K, etc.) |\n",
    "| `Card_Category`            | Credit card type (Blue, Silver, Gold, Platinum)       |\n",
    "| `Months_on_book`           | Tenure with the bank (in months)                      |\n",
    "| `Total_Relationship_Count` | Total number of bank products held                    |\n",
    "| `Months_Inactive_12_mon`   | Inactive months in the past 12 months                 |\n",
    "| `Contacts_Count_12_mon`    | Customer service contacts in the past 12 months       |\n",
    "| `Credit_Limit`             | Credit card limit                                     |\n",
    "| `Total_Revolving_Bal`      | Revolving balance on the card                         |\n",
    "| `Avg_Open_To_Buy`          | Average available credit                              |\n",
    "| `Total_Trans_Amt`          | Total transaction amount in last 12 months            |\n",
    "| `Total_Trans_Ct`           | Total transaction count in last 12 months             |\n",
    "| `Total_Ct_Chng_Q4_Q1`      | Change in transaction count Q4 vs Q1                  |\n",
    "| `Total_Amt_Chng_Q4_Q1`     | Change in transaction amount Q4 vs Q1                 |\n",
    "| `Avg_Utilization_Ratio`    | Average card utilization rate                         |\n",
    "\n",
    "**Files Provided**\n",
    "\n",
    "* `BankChurners.csv`: Main dataset including both input features and target variable.\n",
    "\n",
    "**Project Objective**\n",
    "\n",
    "The goal of this notebook is to **analyze customer behavior and predict churn**, supporting business decisions like:\n",
    "\n",
    "* Targeted retention strategies\n",
    "* Personalized offers for at-risk customers\n",
    "* Reducing customer attrition\n",
    "\n",
    "**Key Steps**\n",
    "\n",
    "* **Exploratory Data Analysis (EDA):** <br>\n",
    "  Understand patterns in customer behavior and churn.\n",
    "\n",
    "* **üõ† Feature Engineering:**\n",
    "  Encode categorical variables, scale numerical features, and create meaningful derived variables (e.g. utilization ratios, transaction trends).\n",
    "\n",
    "* **Modeling:**\n",
    "  Apply various classifiers like:\n",
    "\n",
    "  * Logistic Regression\n",
    "  * Random Forest\n",
    "  * XGBoost\n",
    "  * LightGBM\n",
    "  * MLPClassifier\n",
    "  ...\n",
    "\n",
    "* **Evaluation Framework:**\n",
    "\n",
    "  * Use **Stratified Cross-Validation**\n",
    "  * Assess using:\n",
    "\n",
    "    * Accuracy\n",
    "    * Precision\n",
    "    * Recall\n",
    "    * F1-score\n",
    "    * ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76715678",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Import Libraries</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Import Libraries\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37e158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Display utilities for Jupyter notebooks\n",
    "from IPython.display import display\n",
    "\n",
    "# Machine learning preprocessing and modeling\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# Statistical\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import shapiro, probplot\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import kruskal\n",
    "from scipy.stats import anderson\n",
    "from scipy.stats import normaltest\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 500) # To display all the columns of dataframe\n",
    "pd.set_option(\"max_colwidth\", None) # To set the width of the column to maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5edf8e",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Load Data</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Load Data\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cd0056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a382a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (10127, 23)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bank Customer Churn\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read CSV file into Spark DataFrame\n",
    "df_customer_churn = spark.read.csv(\"BankChurners.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the number of rows and columns\n",
    "print(\"Data Shape:\", (df_customer_churn.count(), len(df_customer_churn.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd5e0e",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Data Preview and Info</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Data Preview and Info\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f25d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "+---------+-----------------+------------+------+---------------+---------------+--------------+---------------+-------------+--------------+------------------------+----------------------+---------------------+------------+-------------------+---------------+--------------------+---------------+--------------+-------------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|CLIENTNUM|   Attrition_Flag|Customer_Age|Gender|Dependent_count|Education_Level|Marital_Status|Income_Category|Card_Category|Months_on_book|Total_Relationship_Count|Months_Inactive_12_mon|Contacts_Count_12_mon|Credit_Limit|Total_Revolving_Bal|Avg_Open_To_Buy|Total_Amt_Chng_Q4_Q1|Total_Trans_Amt|Total_Trans_Ct|Total_Ct_Chng_Q4_Q1|Avg_Utilization_Ratio|Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1|Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2|\n",
      "+---------+-----------------+------------+------+---------------+---------------+--------------+---------------+-------------+--------------+------------------------+----------------------+---------------------+------------+-------------------+---------------+--------------------+---------------+--------------+-------------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|768805383|Existing Customer|          45|     M|              3|    High School|       Married|    $60K - $80K|         Blue|            39|                       5|                     1|                    3|     12691.0|                777|        11914.0|               1.335|           1144|            42|              1.625|                0.061|                                                                                                                         9.3448E-5|                                                                                                                           0.99991|\n",
      "|818770008|Existing Customer|          49|     F|              5|       Graduate|        Single| Less than $40K|         Blue|            44|                       6|                     1|                    2|      8256.0|                864|         7392.0|               1.541|           1291|            33|              3.714|                0.105|                                                                                                                         5.6861E-5|                                                                                                                           0.99994|\n",
      "|713982108|Existing Customer|          51|     M|              3|       Graduate|       Married|   $80K - $120K|         Blue|            36|                       4|                     1|                    0|      3418.0|                  0|         3418.0|               2.594|           1887|            20|              2.333|                  0.0|                                                                                                                         2.1081E-5|                                                                                                                           0.99998|\n",
      "|769911858|Existing Customer|          40|     F|              4|    High School|       Unknown| Less than $40K|         Blue|            34|                       3|                     4|                    1|      3313.0|               2517|          796.0|               1.405|           1171|            20|              2.333|                 0.76|                                                                                                                         1.3366E-4|                                                                                                                           0.99987|\n",
      "|709106358|Existing Customer|          40|     M|              3|     Uneducated|       Married|    $60K - $80K|         Blue|            21|                       5|                     1|                    0|      4716.0|                  0|         4716.0|               2.175|            816|            28|                2.5|                  0.0|                                                                                                                         2.1676E-5|                                                                                                                           0.99998|\n",
      "|713061558|Existing Customer|          44|     M|              2|       Graduate|       Married|    $40K - $60K|         Blue|            36|                       3|                     1|                    2|      4010.0|               1247|         2763.0|               1.376|           1088|            24|              0.846|                0.311|                                                                                                                         5.5077E-5|                                                                                                                           0.99994|\n",
      "|810347208|Existing Customer|          51|     M|              4|        Unknown|       Married|        $120K +|         Gold|            46|                       6|                     1|                    3|     34516.0|               2264|        32252.0|               1.975|           1330|            31|              0.722|                0.066|                                                                                                                         1.2303E-4|                                                                                                                           0.99988|\n",
      "|818906208|Existing Customer|          32|     M|              0|    High School|       Unknown|    $60K - $80K|       Silver|            27|                       2|                     2|                    2|     29081.0|               1396|        27685.0|               2.204|           1538|            36|              0.714|                0.048|                                                                                                                         8.5795E-5|                                                                                                                           0.99991|\n",
      "|710930508|Existing Customer|          37|     M|              3|     Uneducated|        Single|    $60K - $80K|         Blue|            36|                       5|                     2|                    0|     22352.0|               2517|        19835.0|               3.355|           1350|            24|              1.182|                0.113|                                                                                                                         4.4796E-5|                                                                                                                           0.99996|\n",
      "|719661558|Existing Customer|          48|     M|              2|       Graduate|        Single|   $80K - $120K|         Blue|            36|                       6|                     3|                    3|     11656.0|               1677|         9979.0|               1.524|           1441|            32|              0.882|                0.144|                                                                                                                         3.0251E-4|                                                                                                                            0.9997|\n",
      "+---------+-----------------+------------+------+---------------+---------------+--------------+---------------+-------------+--------------+------------------------+----------------------+---------------------+------------+-------------------+---------------+--------------------+---------------+--------------+-------------------+---------------------+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a few rows of the dataset\n",
    "print(\"Data Preview:\")\n",
    "df_customer_churn.show(10)   # Show 5 rows = df_customer_churn.head() with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe81ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "+---------+-----------------+------------+------+---------------+---------------+--------------+---------------+-------------+--------------+------------------------+----------------------+---------------------+------------+-------------------+---------------+--------------------+---------------+--------------+-------------------+---------------------+\n",
      "|CLIENTNUM|   Attrition_Flag|Customer_Age|Gender|Dependent_count|Education_Level|Marital_Status|Income_Category|Card_Category|Months_on_book|Total_Relationship_Count|Months_Inactive_12_mon|Contacts_Count_12_mon|Credit_Limit|Total_Revolving_Bal|Avg_Open_To_Buy|Total_Amt_Chng_Q4_Q1|Total_Trans_Amt|Total_Trans_Ct|Total_Ct_Chng_Q4_Q1|Avg_Utilization_Ratio|\n",
      "+---------+-----------------+------------+------+---------------+---------------+--------------+---------------+-------------+--------------+------------------------+----------------------+---------------------+------------+-------------------+---------------+--------------------+---------------+--------------+-------------------+---------------------+\n",
      "|768805383|Existing Customer|          45|     M|              3|    High School|       Married|    $60K - $80K|         Blue|            39|                       5|                     1|                    3|     12691.0|                777|        11914.0|               1.335|           1144|            42|              1.625|                0.061|\n",
      "|818770008|Existing Customer|          49|     F|              5|       Graduate|        Single| Less than $40K|         Blue|            44|                       6|                     1|                    2|      8256.0|                864|         7392.0|               1.541|           1291|            33|              3.714|                0.105|\n",
      "|713982108|Existing Customer|          51|     M|              3|       Graduate|       Married|   $80K - $120K|         Blue|            36|                       4|                     1|                    0|      3418.0|                  0|         3418.0|               2.594|           1887|            20|              2.333|                  0.0|\n",
      "|769911858|Existing Customer|          40|     F|              4|    High School|       Unknown| Less than $40K|         Blue|            34|                       3|                     4|                    1|      3313.0|               2517|          796.0|               1.405|           1171|            20|              2.333|                 0.76|\n",
      "|709106358|Existing Customer|          40|     M|              3|     Uneducated|       Married|    $60K - $80K|         Blue|            21|                       5|                     1|                    0|      4716.0|                  0|         4716.0|               2.175|            816|            28|                2.5|                  0.0|\n",
      "|713061558|Existing Customer|          44|     M|              2|       Graduate|       Married|    $40K - $60K|         Blue|            36|                       3|                     1|                    2|      4010.0|               1247|         2763.0|               1.376|           1088|            24|              0.846|                0.311|\n",
      "|810347208|Existing Customer|          51|     M|              4|        Unknown|       Married|        $120K +|         Gold|            46|                       6|                     1|                    3|     34516.0|               2264|        32252.0|               1.975|           1330|            31|              0.722|                0.066|\n",
      "|818906208|Existing Customer|          32|     M|              0|    High School|       Unknown|    $60K - $80K|       Silver|            27|                       2|                     2|                    2|     29081.0|               1396|        27685.0|               2.204|           1538|            36|              0.714|                0.048|\n",
      "|710930508|Existing Customer|          37|     M|              3|     Uneducated|        Single|    $60K - $80K|         Blue|            36|                       5|                     2|                    0|     22352.0|               2517|        19835.0|               3.355|           1350|            24|              1.182|                0.113|\n",
      "|719661558|Existing Customer|          48|     M|              2|       Graduate|        Single|   $80K - $120K|         Blue|            36|                       6|                     3|                    3|     11656.0|               1677|         9979.0|               1.524|           1441|            32|              0.882|                0.144|\n",
      "+---------+-----------------+------------+------+---------------+---------------+--------------+---------------+-------------+--------------+------------------------+----------------------+---------------------+------------+-------------------+---------------+--------------------+---------------+--------------+-------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop multiple columns at once\n",
    "df_customer_churn = df_customer_churn.drop(\n",
    "    \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\n",
    "    \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"\n",
    ")\n",
    "\n",
    "# Display a few rows of the dataset\n",
    "print(\"Data Preview:\")\n",
    "df_customer_churn.show(10)   # Show 5 rows = df_customer_churn.head() with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d501c9",
   "metadata": {},
   "source": [
    "## Insights from Initial Data Exploration\n",
    "\n",
    "**Dataset Size and Structure**  \n",
    "   - The **dataset** contains **10127** samples with **23** columns, including the target variable `Attrition_Flag`.\n",
    "\n",
    "**Feature Overview**  \n",
    "   - Both datasets include all important attributes:\n",
    "     - **Numerical features:** `Customer_Age`, `Dependent_count`, `Months_on_book`, `Total_Relationship_Count`, `Months_Inactive_12_mon`, `Contacts_Count_12_mon`, `Credit_Limit`, `Total_Revolving_Bal`, `Avg_Open_To_Buy`, `Total_Trans_Amt`, `Total_Trans_Ct`, `Total_Ct_Chng_Q4_Q1`, `Total_Amt_Chng_Q4_Q1` and `Avg_Utilization_Ratio`.\n",
    "     - **Categorical features:** `Attrition_Flag`, `Gender`, `Education_Level`, `Marital_Status`, `Income_Category`, `Card_Category`.\n",
    "   - The target variable is **object** value.\n",
    "\n",
    "**Data Completeness**  \n",
    "   - Data types are appropriate: numerical features is float64 and int64, and categorical features are objects (strings).\n",
    "   - The columns `Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1`, `Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2` are not meaningful for analysis. So these columns are not really a part of the information we should care about. We can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7cc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all column names\n",
    "for col in df_customer_churn.columns:\n",
    "    # Rename each column by stripping leading/trailing whitespaces\n",
    "    df_customer_churn = df_customer_churn.withColumnRenamed(col, col.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a040a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10127, 21)\n",
      "Summary Statistics for Numerical Features:\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+------------------+-----------------+-------------------+--------------------+---------------------+-------------------+\n",
      "|summary|     Customer_Age|     Credit_Limit|  Avg_Open_To_Buy|  Total_Trans_Amt|    Months_on_book|   Total_Trans_Ct|Total_Ct_Chng_Q4_Q1|Total_Amt_Chng_Q4_Q1|Avg_Utilization_Ratio|Total_Revolving_Bal|\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+------------------+-----------------+-------------------+--------------------+---------------------+-------------------+\n",
      "|  count|            10127|            10127|            10127|            10127|             10127|            10127|              10127|               10127|                10127|              10127|\n",
      "|   mean|46.32596030413745|8631.953698034848|7469.139636614887|4404.086303939963|35.928409203120374|64.85869457884863| 0.7122223758269962|  0.7599406536980376|   0.2748935518909845| 1162.8140614199665|\n",
      "| stddev|8.016814032549046|9088.776650223148|9090.685323679114|3397.129253557085|  7.98641633087208|23.47257044923301|0.23808609133294137|  0.2192067692307027|  0.27569146925238736|  814.9873352357533|\n",
      "|    min|               26|           1438.3|              3.0|              510|                13|               10|                0.0|                 0.0|                  0.0|                  0|\n",
      "|    25%|               41|           2555.0|           1322.0|             2155|                31|               45|              0.581|               0.631|                0.022|                357|\n",
      "|    50%|               46|           4549.0|           3472.0|             3899|                36|               67|              0.702|               0.736|                0.175|               1276|\n",
      "|    75%|               52|          11067.0|           9857.0|             4741|                40|               81|              0.818|               0.859|                0.503|               1784|\n",
      "|    max|               73|          34516.0|          34516.0|            18484|                56|              139|              3.714|               3.397|                0.999|               2517|\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+------------------+-----------------+-------------------+--------------------+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features = [\"Customer_Age\", \"Credit_Limit\", \"Avg_Open_To_Buy\", \"Total_Trans_Amt\", \"Months_on_book\", \n",
    "                \"Total_Trans_Ct\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Amt_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\", \"Total_Revolving_Bal\"]\n",
    "\n",
    "# Display number of rows and columns\n",
    "print(\"Shape:\", (df_customer_churn.count(), len(df_customer_churn.columns)))\n",
    "\n",
    "# Display summary statistics only for selected numerical features\n",
    "print(\"Summary Statistics for Numerical Features:\")\n",
    "df_customer_churn.select(num_features).summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343ac85",
   "metadata": {},
   "source": [
    "## Descriptive Insights ‚Äì Numerical Features\n",
    "\n",
    "**1. Demographics & Tenure**\n",
    "\n",
    "* **Customer Age**\n",
    "\n",
    "  * Mean: **46.3 years** | Range: 26‚Äì73\n",
    "  * 25‚Äì75%: **41‚Äì52** ‚Üí Primarily middle-aged adults\n",
    "  * Std: 8.0 ‚Üí Fairly even distribution\n",
    "\n",
    "* **Months on Book** (Tenure)\n",
    "\n",
    "  * Mean: **35.9 months** (\\~3 years)\n",
    "  * 25‚Äì75%: **31‚Äì40** ‚Üí Most customers have stayed for 2.5‚Äì3.5 years\n",
    "  * Std: 8.0 ‚Üí Moderate spread\n",
    "\n",
    "**2. Credit Behavior**\n",
    "\n",
    "* **Credit Limit**\n",
    "\n",
    "  * Mean: **\\$8,632** | Max: \\$34,516\n",
    "  * 25‚Äì75%: **\\$4,549‚Äì\\$11,068**\n",
    "  * Std: **\\$9,089** ‚Üí Highly dispersed, potential right-skewness\n",
    "\n",
    "* **Avg Open to Buy**\n",
    "\n",
    "  * Mean: **\\$7,469** (closely follows `Credit_Limit`)\n",
    "  * Std: **\\$9,091** ‚Üí Strong dependency between the two\n",
    "\n",
    "* **Avg Utilization Ratio**\n",
    "\n",
    "  * Mean: **27.5%**\n",
    "  * 25‚Äì75%: **2.3%‚Äì50.3%** | Max: \\~**99.9%**\n",
    "  * ‚Üí Some customers nearly max out their limits ‚Üí Potential risk or loyal high spenders\n",
    "\n",
    "* **Total Revolving Balance**\n",
    "\n",
    "  * Mean: **\\$1,162**\n",
    "  * 25‚Äì75%: **\\$359‚Äì\\$1,784**\n",
    "  * Std: **\\$815** ‚Üí Wide variability, warrants skewness check\n",
    "\n",
    "**3. Transaction Behavior**\n",
    "\n",
    "* **Total Transaction Amount**\n",
    "\n",
    "  * Mean: **\\$4,404** | Max: \\$18,484\n",
    "  * 25‚Äì75%: **\\$2,156‚Äì\\$4,741**\n",
    "  * Std: **\\$3,397** ‚Üí Outliers likely among high spenders\n",
    "\n",
    "* **Total Transaction Count**\n",
    "\n",
    "  * Mean: **\\~65 transactions/year**\n",
    "  * 25‚Äì75%: **45‚Äì81 transactions**\n",
    "  * Std: 23.5 ‚Üí Ranges from light to highly active users\n",
    "\n",
    "**4. Behavioral Changes**\n",
    "\n",
    "* **Total Amt Change Q4/Q1**\n",
    "\n",
    "  * Mean: **0.76** | Max: **3.40**\n",
    "  * 25‚Äì75%: **0.63‚Äì0.86**\n",
    "  * ‚Üí Some customers drastically increased spending in Q4 ‚Üí May signal churn or upsell opportunity\n",
    "\n",
    "* **Total Ct Change Q4/Q1**\n",
    "\n",
    "  * Mean: **0.71**\n",
    "  * Std: 0.24 ‚Üí Frequency shifts may indicate behavioral trends\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* **Credit and transaction features show high variance** ‚Üí Consider scaling or transformation\n",
    "* **Age and tenure are more normally distributed** ‚Üí Easier to model\n",
    "* Features like `Total_Amt_Chng_Q4_Q1`, `Avg_Utilization_Ratio`, and `Total_Revolving_Bal` exhibit **strong financial behavior patterns** ‚Üí Valuable churn predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de953fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# List of categorical features that we want to ensure are stored as strings\n",
    "cat_features = [\n",
    "    \"Attrition_Flag\", \"Gender\", \"Education_Level\", \"Marital_Status\",\n",
    "    \"Income_Category\", \"Card_Category\", \"Dependent_count\",\n",
    "    \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Total_Relationship_Count\"\n",
    "]\n",
    "\n",
    "# Function to convert categorical features to StringType\n",
    "def convert_cat(df, cat_features):\n",
    "    for feature in cat_features:\n",
    "        # Check if the column exists in the DataFrame\n",
    "        if feature in df.columns:\n",
    "            # Cast the column to StringType to ensure it's treated as categorical\n",
    "            df = df.withColumn(feature, df[feature].cast(StringType()))\n",
    "    return df\n",
    "\n",
    "# Apply conversion to the customer churn DataFrame\n",
    "df_customer_churn = convert_cat(df_customer_churn, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b44cd4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "root\n",
      " |-- CLIENTNUM: integer (nullable = true)\n",
      " |-- Attrition_Flag: string (nullable = true)\n",
      " |-- Customer_Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Dependent_count: string (nullable = true)\n",
      " |-- Education_Level: string (nullable = true)\n",
      " |-- Marital_Status: string (nullable = true)\n",
      " |-- Income_Category: string (nullable = true)\n",
      " |-- Card_Category: string (nullable = true)\n",
      " |-- Months_on_book: integer (nullable = true)\n",
      " |-- Total_Relationship_Count: string (nullable = true)\n",
      " |-- Months_Inactive_12_mon: string (nullable = true)\n",
      " |-- Contacts_Count_12_mon: string (nullable = true)\n",
      " |-- Credit_Limit: double (nullable = true)\n",
      " |-- Total_Revolving_Bal: integer (nullable = true)\n",
      " |-- Avg_Open_To_Buy: double (nullable = true)\n",
      " |-- Total_Amt_Chng_Q4_Q1: double (nullable = true)\n",
      " |-- Total_Trans_Amt: integer (nullable = true)\n",
      " |-- Total_Trans_Ct: integer (nullable = true)\n",
      " |-- Total_Ct_Chng_Q4_Q1: double (nullable = true)\n",
      " |-- Avg_Utilization_Ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema (column names and data types)\n",
    "print(\"Data Info:\")\n",
    "df_customer_churn.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f466a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8896c_row0_col1, #T_8896c_row1_col1, #T_8896c_row9_col3 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row0_col3 {\n",
       "  background-color: #09529d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8896c_row1_col3 {\n",
       "  background-color: #89bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row2_col1, #T_8896c_row5_col3, #T_8896c_row7_col1, #T_8896c_row8_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8896c_row2_col3 {\n",
       "  background-color: #e0ecf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row3_col1, #T_8896c_row5_col1 {\n",
       "  background-color: #94c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row3_col3 {\n",
       "  background-color: #abd0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row4_col1, #T_8896c_row6_col1, #T_8896c_row9_col1 {\n",
       "  background-color: #1764ab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8896c_row4_col3 {\n",
       "  background-color: #d4e4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row6_col3 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row7_col3 {\n",
       "  background-color: #cddff1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8896c_row8_col3 {\n",
       "  background-color: #d9e8f5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8896c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8896c_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n",
       "      <th id=\"T_8896c_level0_col1\" class=\"col_heading level0 col1\" >unique</th>\n",
       "      <th id=\"T_8896c_level0_col2\" class=\"col_heading level0 col2\" >top</th>\n",
       "      <th id=\"T_8896c_level0_col3\" class=\"col_heading level0 col3\" >freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row0\" class=\"row_heading level0 row0\" >Attrition_Flag</th>\n",
       "      <td id=\"T_8896c_row0_col0\" class=\"data row0 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_8896c_row0_col2\" class=\"data row0 col2\" >Existing Customer</td>\n",
       "      <td id=\"T_8896c_row0_col3\" class=\"data row0 col3\" >8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row1\" class=\"row_heading level0 row1\" >Gender</th>\n",
       "      <td id=\"T_8896c_row1_col0\" class=\"data row1 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_8896c_row1_col2\" class=\"data row1 col2\" >F</td>\n",
       "      <td id=\"T_8896c_row1_col3\" class=\"data row1 col3\" >5358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row2\" class=\"row_heading level0 row2\" >Education_Level</th>\n",
       "      <td id=\"T_8896c_row2_col0\" class=\"data row2 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row2_col1\" class=\"data row2 col1\" >7</td>\n",
       "      <td id=\"T_8896c_row2_col2\" class=\"data row2 col2\" >Graduate</td>\n",
       "      <td id=\"T_8896c_row2_col3\" class=\"data row2 col3\" >3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row3\" class=\"row_heading level0 row3\" >Marital_Status</th>\n",
       "      <td id=\"T_8896c_row3_col0\" class=\"data row3 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row3_col1\" class=\"data row3 col1\" >4</td>\n",
       "      <td id=\"T_8896c_row3_col2\" class=\"data row3 col2\" >Married</td>\n",
       "      <td id=\"T_8896c_row3_col3\" class=\"data row3 col3\" >4687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row4\" class=\"row_heading level0 row4\" >Income_Category</th>\n",
       "      <td id=\"T_8896c_row4_col0\" class=\"data row4 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row4_col1\" class=\"data row4 col1\" >6</td>\n",
       "      <td id=\"T_8896c_row4_col2\" class=\"data row4 col2\" >Less than $40K</td>\n",
       "      <td id=\"T_8896c_row4_col3\" class=\"data row4 col3\" >3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row5\" class=\"row_heading level0 row5\" >Card_Category</th>\n",
       "      <td id=\"T_8896c_row5_col0\" class=\"data row5 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row5_col1\" class=\"data row5 col1\" >4</td>\n",
       "      <td id=\"T_8896c_row5_col2\" class=\"data row5 col2\" >Blue</td>\n",
       "      <td id=\"T_8896c_row5_col3\" class=\"data row5 col3\" >9436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row6\" class=\"row_heading level0 row6\" >Dependent_count</th>\n",
       "      <td id=\"T_8896c_row6_col0\" class=\"data row6 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row6_col1\" class=\"data row6 col1\" >6</td>\n",
       "      <td id=\"T_8896c_row6_col2\" class=\"data row6 col2\" >3</td>\n",
       "      <td id=\"T_8896c_row6_col3\" class=\"data row6 col3\" >2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row7\" class=\"row_heading level0 row7\" >Months_Inactive_12_mon</th>\n",
       "      <td id=\"T_8896c_row7_col0\" class=\"data row7 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "      <td id=\"T_8896c_row7_col2\" class=\"data row7 col2\" >3</td>\n",
       "      <td id=\"T_8896c_row7_col3\" class=\"data row7 col3\" >3846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row8\" class=\"row_heading level0 row8\" >Contacts_Count_12_mon</th>\n",
       "      <td id=\"T_8896c_row8_col0\" class=\"data row8 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row8_col1\" class=\"data row8 col1\" >7</td>\n",
       "      <td id=\"T_8896c_row8_col2\" class=\"data row8 col2\" >3</td>\n",
       "      <td id=\"T_8896c_row8_col3\" class=\"data row8 col3\" >3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8896c_level0_row9\" class=\"row_heading level0 row9\" >Total_Relationship_Count</th>\n",
       "      <td id=\"T_8896c_row9_col0\" class=\"data row9 col0\" >10127</td>\n",
       "      <td id=\"T_8896c_row9_col1\" class=\"data row9 col1\" >6</td>\n",
       "      <td id=\"T_8896c_row9_col2\" class=\"data row9 col2\" >3</td>\n",
       "      <td id=\"T_8896c_row9_col3\" class=\"data row9 col3\" >2305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1907f7432b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def describe_categorical(df, cat_features):\n",
    "    results = {}\n",
    "    for col in cat_features:\n",
    "        if col in df.columns:\n",
    "            # total count (non-null)\n",
    "            total = df.select(F.count(col)).collect()[0][0]\n",
    "            # unique count\n",
    "            unique = df.select(col).distinct().count()\n",
    "            # most frequent value\n",
    "            top_val = df.groupBy(col).count().orderBy(F.desc(\"count\")).first()\n",
    "            results[col] = {\n",
    "                \"count\": total,\n",
    "                \"unique\": unique,\n",
    "                \"top\": top_val[0],\n",
    "                \"freq\": top_val[1]\n",
    "            }\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "cat_summary = describe_categorical(df_customer_churn, cat_features)\n",
    "# for k, v in cat_summary.items():\n",
    "#     print(k, \":\", v)\n",
    "display(pd.DataFrame(cat_summary).T.style.background_gradient(cmap=\"Blues\", subset=[\"unique\", \"freq\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1b60c",
   "metadata": {},
   "source": [
    "## Descriptive Insights from Categorical Features\n",
    "\n",
    "`Attrition_Flag` *(Target Variable)*\n",
    "\n",
    "* Two classes:\n",
    "  `Existing Customer` ‚Äì 85.0%\n",
    "  `Attrited Customer` ‚Äì 15.0%\n",
    "* **Observation:** Highly imbalanced ‚Üí Resampling or class weighting needed\n",
    "\n",
    "`Gender`\n",
    "\n",
    "* Two values: `F`, `M`\n",
    "* Majority: Female (‚âà 52.9%)\n",
    "* **Insight:** Balanced distribution ‚Üí Can be used in segmentation or churn analysis\n",
    "\n",
    "`Dependent_count`\n",
    "\n",
    "* 6 unique values (0‚Äì5)\n",
    "* Most frequent: 3 dependents (2,732 customers)\n",
    "* **Insight:** Represents family responsibility ‚Üí Consider ordinal treatment\n",
    "\n",
    "`Education_Level`\n",
    "\n",
    "* 7 levels, top category: `Graduate` (3,128)\n",
    "* **Insight:** Relevant for income segmentation and credit behavior analysis\n",
    "\n",
    "`Marital_Status`\n",
    "\n",
    "* 4 values, most common: `Married` (4,687)\n",
    "* **Insight:** May impact spending behavior ‚Üí Check churn across groups\n",
    "\n",
    "`Income_Category`\n",
    "\n",
    "* 6 income brackets\n",
    "* Most frequent: `Less than $40K` (3,561)\n",
    "* **Insight:** Skewed toward lower-income segment ‚Üí May affect product usage\n",
    "\n",
    "`Card_Category`\n",
    "\n",
    "* 4 categories, heavily skewed toward `Blue` (‚âà 93%)\n",
    "* **Insight:** Highly imbalanced ‚Üí Consider grouping or frequency encoding\n",
    "\n",
    "`Total_Relationship_Count`\n",
    "\n",
    "* 6 values, most common: 3 (2,305 customers)\n",
    "* **Insight:** Reflects product engagement ‚Üí Key indicator of customer loyalty\n",
    "\n",
    "`Months_Inactive_12_mon`\n",
    "\n",
    "* 7 values, peak at 3 months (3,846 customers)\n",
    "* **Insight:** Strong behavioral feature ‚Üí Linked to potential churn risk\n",
    "\n",
    "`Contacts_Count_12_mon`\n",
    "\n",
    "* 7 levels, most common: 3 contacts/year (3,380)\n",
    "* **Insight:** Indicates engagement with bank ‚Üí Analyze correlation with churn\n",
    "\n",
    "**Summary of Key Observations**\n",
    "\n",
    "| Key Finding                                        | Suggested Next Step                             |\n",
    "| -------------------------------------------------- | ----------------------------------------------- |\n",
    "| Target is imbalanced (85% vs. 15%)                 | Apply resampling or class weights               |\n",
    "| Card type is skewed toward `Blue`                  | Group rare categories or use frequency encoding |\n",
    "| Behavioral features show clear usage patterns      | Leverage for churn prediction                   |\n",
    "| Some features are ordinal (`Income`, `Dependents`) | Consider ordinal encoding or binning            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b49c7",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Data Quality Checks</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Data Quality Checks\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37d427",
   "metadata": {},
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "üîé Missing Value Summary for: Bank Customer Churn\n",
      "========================================\n",
      "‚úÖ No missing values detected in 10,127 rows.\n"
     ]
    }
   ],
   "source": [
    "def displayNULL(df, dataset_name=None):\n",
    "    # Total number of rows in the DataFrame\n",
    "    total_rows = df.count()\n",
    "\n",
    "    # Compute missing values per column\n",
    "    # SELECT\n",
    "    # COUNT(CASE WHEN col1 IS NULL OR isnan(col1) THEN 1 END) AS col1,\n",
    "    # COUNT(CASE WHEN col2 IS NULL OR isnan(col2) THEN 1 END) AS col2,\n",
    "    # COUNT(CASE WHEN col3 IS NULL OR isnan(col3) THEN 1 END) AS col3,\n",
    "    # ...\n",
    "    # FROM df;\n",
    "\n",
    "    missing_stats = (\n",
    "        df.select([\n",
    "            F.count(F.when(F.col(c).isNull() | F.isnan(F.col(c)), c)).alias(c)\n",
    "            for c in df.columns\n",
    "        ])\n",
    "        .toPandas()\n",
    "        .T.reset_index()\n",
    "    )\n",
    "\n",
    "    missing_stats.columns = [\"Feature\", \"Missing_Count\"]\n",
    "    # Keep only columns with missing values\n",
    "    missing_stats = missing_stats[missing_stats[\"Missing_Count\"] > 0]\n",
    "    # Compute percentage of missing values\n",
    "    missing_stats[\"Missing_%\"] = (missing_stats[\"Missing_Count\"] / total_rows * 100).round(2)\n",
    "    # Sort by missing count\n",
    "    missing_stats = missing_stats.sort_values(by=\"Missing_Count\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Total missing values across the dataset\n",
    "    total_missing = missing_stats[\"Missing_Count\"].sum()\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    if dataset_name:\n",
    "        print(f\"üîé Missing Value Summary for: {dataset_name}\")\n",
    "    else:\n",
    "        print(\"üîé Missing Value Summary:\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    if total_missing == 0:\n",
    "        print(f\"‚úÖ No missing values detected in {total_rows:,} rows.\")\n",
    "    else:\n",
    "        try:\n",
    "            from tabulate import tabulate\n",
    "            print(tabulate(missing_stats, headers=\"keys\", tablefmt=\"pretty\", showindex=False, colalign=(\"left\", \"right\", \"right\")))\n",
    "        except ImportError:\n",
    "            print(missing_stats.to_string(index=False))\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Total missing values: {total_missing:,} out of {total_rows:,} rows.\")\n",
    "\n",
    "displayNULL(df_customer_churn, dataset_name=\"Bank Customer Churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fad581",
   "metadata": {},
   "source": [
    "## Checking duplicate Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e83fb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "üîç Bank Customer Churn Duplicate Analysis\n",
      "========================================\n",
      "‚úÖ No duplicates found in 10,127 rows\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates_report(df, dataset_name):\n",
    "    # Total number of rows\n",
    "    total_rows = df.count()\n",
    "\n",
    "    # Group by all columns and count occurrences\n",
    "    dup_df = (\n",
    "        df.groupBy(df.columns)\n",
    "          .count()\n",
    "          .filter(F.col(\"count\") > 1)   # only keep duplicate rows\n",
    "    )\n",
    "\n",
    "    # Number of duplicate rows = sum(count) - number of distinct rows\n",
    "    if dup_df.count() == 0:\n",
    "        duplicates_count = 0\n",
    "    else:\n",
    "        duplicates_count = dup_df.agg(F.sum(\"count\")).collect()[0][0] - dup_df.count()\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üîç {dataset_name} Duplicate Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    if duplicates_count == 0:\n",
    "        print(f\"‚úÖ No duplicates found in {total_rows:,} rows\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {duplicates_count} duplicates found ({duplicates_count/total_rows:.2%})\")\n",
    "        print(f\"    Total rows affected: {duplicates_count:,}/{total_rows:,}\")\n",
    "\n",
    "    return duplicates_count, total_rows\n",
    "\n",
    "duplicates_count, total_rows = check_duplicates_report(df_customer_churn, \"Bank Customer Churn\")\n",
    "\n",
    "duplicate_summary = {\n",
    "    \"Bank Customer Churn\": {\n",
    "        \"duplicates\": duplicates_count,\n",
    "        \"total_rows\": total_rows\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e598047",
   "metadata": {},
   "source": [
    "## Checking Outlier Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34cb7207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "üîç Bank Customer Churn Checking outlier\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Outlier Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer_Age</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit_Limit</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avg_Open_To_Buy</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total_Trans_Amt</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Months_on_book</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total_Trans_Ct</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total_Ct_Chng_Q4_Q1</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total_Amt_Chng_Q4_Q1</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Outlier Count\n",
       "0          Customer_Age              2\n",
       "1          Credit_Limit            984\n",
       "2       Avg_Open_To_Buy            962\n",
       "3       Total_Trans_Amt            895\n",
       "4        Months_on_book            386\n",
       "5        Total_Trans_Ct              2\n",
       "6   Total_Ct_Chng_Q4_Q1            394\n",
       "7  Total_Amt_Chng_Q4_Q1            396"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checking_outlier(list_feature, df, dataset_name):\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üîç {dataset_name} Checking outlier\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    outlier_info = []\n",
    "\n",
    "    for feature in list_feature:\n",
    "        # Calculate Q1 and Q3 using approxQuantile\n",
    "        Q1, Q3 = df.approxQuantile(feature, [0.25, 0.75], 0)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Count number of outliers\n",
    "        outliers_count = df.filter((F.col(feature) < lower_bound) | (F.col(feature) > upper_bound)).count()\n",
    "\n",
    "        if outliers_count > 0:\n",
    "            outlier_info.append({\n",
    "                \"Feature\": feature,\n",
    "                \"Outlier Count\": outliers_count\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(outlier_info)\n",
    "\n",
    "checking_outlier(list_feature=num_features, df=df_customer_churn, dataset_name=\"Bank Customer Churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc08ca",
   "metadata": {},
   "source": [
    "## Data Quality Insights: Missing Values, Duplicates and Outliers\n",
    "\n",
    "**Missing Values Analysis**\n",
    "\n",
    "- We conducted a thorough check for missing values across the datasets.  \n",
    "- **No missing values** in the datasets.\n",
    "\n",
    "**Duplicate Records Analysis**\n",
    "\n",
    "- We examined the datasets for duplicate rows that could bias the model or inflate performance metrics.  \n",
    "- **No duplicate records** were found in any dataset, confirming the uniqueness and integrity of each sample:  \n",
    "  - Data: 0 duplicate out of `10127` rows.\n",
    "- The absence of duplicates ensures that the model will not be trained or evaluated on repeated data points, which helps maintain the reliability of results.\n",
    "\n",
    "**Outliers Records Analysis**\n",
    "\n",
    "- We also examined the datasets for checking outliers.\n",
    "- **The outliers** were found in dataset at features. But we can not remove them since these outliers reflect reality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ac8a6",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Exploratory Data Analysis</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Exploratory Data Analysis\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf73dd",
   "metadata": {},
   "source": [
    "**Statistical**\n",
    "\n",
    "‚úÖ Are the Assumptions of T-Test and ANOVA the Same?\n",
    "Yes ‚Äî T-Test and ANOVA share very similar assumptions, as both are parametric tests used to compare group means. However, there are slight differences due to their intended use.\n",
    "\n",
    "‚úÖ Common Assumptions for Both T-Test and ANOVA\n",
    "\n",
    "| **Assumption**                 | **T-Test**                                        | **ANOVA**                             |\n",
    "| ------------------------------ | ------------------------------------------------- | ------------------------------------- |\n",
    "| **1. Dependent variable**      | Continuous                                        | Continuous                            |\n",
    "| **2. Grouping variable**       | Categorical with **2 groups**                     | Categorical with **3 or more groups** |\n",
    "| **3. Normality**               | Data in each group should be normally distributed | Same as T-Test                        |\n",
    "| **4. Homogeneity of variance** | Equal variances across groups (`equal_var=True`)  | Same as T-Test                        |\n",
    "| **5. Independence**            | Observations must be independent                  | Same as T-Test                        |\n",
    "\n",
    "üîÑ Key Differences Between T-Test and ANOVA\n",
    "\n",
    "| **Criterion**           | **T-Test**                   | **ANOVA**                                       |\n",
    "| ----------------------- | ---------------------------- | ----------------------------------------------- |\n",
    "| Number of groups        | Compares **2 groups**        | Compares **3 or more groups**                   |\n",
    "| Post-hoc tests required | Not required                 | Required if significant (e.g., **Tukey‚Äôs HSD**) |\n",
    "| Types of tests          | Independent or Paired T-Test | One-Way or Repeated Measures ANOVA              |\n",
    "\n",
    "üìå Alternatives When Assumptions Are Violated\n",
    "\n",
    "| **Violation**           | **T-Test Alternative**  | **ANOVA Alternative**   |\n",
    "| ----------------------- | ----------------------- | ----------------------- |\n",
    "| Non-normal distribution | **Mann‚ÄìWhitney U Test** | **Kruskal‚ÄìWallis Test** |\n",
    "| Unequal variances       | **Welch‚Äôs T-Test**      | **Welch‚Äôs ANOVA**       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb23ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(n_colors=2):\n",
    "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "    positions = np.linspace(0, 1, n_colors)\n",
    "    colors = [cmap(p) for p in positions]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a861c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ChiSquare(cat_feature, target_feature, df, show_expected=False, show_residuals=False):\n",
    "    \"\"\"\n",
    "    Perform a Chi-Square test of independence to evaluate whether two categorical variables \n",
    "    are statistically associated (i.e., dependent) or independent from each other.\n",
    "\n",
    "    This function tests the null hypothesis that the two categorical variables are independent.\n",
    "    It prints the test statistic, degrees of freedom, p-value, and an interpretation based on the p-value.\n",
    "    Optionally, it displays the expected frequency table under independence, and standardized residuals \n",
    "    (including a heatmap) which help to identify specific group-level deviations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cat_feature : str\n",
    "        Name of the first categorical variable (typically the feature).\n",
    "    \n",
    "    target_feature : str\n",
    "        Name of the second categorical variable (typically the target label).\n",
    "    \n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing the data.\n",
    "    \n",
    "    show_expected : bool, default=False\n",
    "        If True, prints the expected frequencies under the assumption of independence.\n",
    "    \n",
    "    show_residuals : bool, default=False\n",
    "        If True, prints the standardized residuals and shows them as a heatmap \n",
    "        to identify where the strongest associations/deviations occur.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the Chi-Square test result, including statistical significance interpretation.\n",
    "        Optionally prints expected values and standardized residuals.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Hypotheses:\n",
    "        H‚ÇÄ (Null):     The two variables are independent (no association).\n",
    "        H‚ÇÅ (Alt.):      There is a dependency or association between the variables.\n",
    "    \n",
    "    - Interpretation:\n",
    "        If p-value < 0.05 ‚Üí Reject H‚ÇÄ ‚Üí Conclude that the variables are significantly associated.\n",
    "        If p-value ‚â• 0.05 ‚Üí Fail to reject H‚ÇÄ ‚Üí No statistically significant association found.\n",
    "\n",
    "    - Standardized residuals:\n",
    "        - Values > +2 or < -2 indicate strong deviation from expected frequency (local dependency).\n",
    "        - Useful for identifying specific group-level contributions to the overall Chi-Square result.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - https://en.wikipedia.org/wiki/Chi-squared_test\n",
    "    - https://www.scribbr.com/statistics/chi-square-test-of-independence/\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nüîç Chi-Square Test of Independence: '{cat_feature}' vs. '{target_feature}'\")\n",
    "\n",
    "    # Build contingency table\n",
    "    crosstab_spark = df.crosstab(cat_feature, target_feature)\n",
    "    crosstab = crosstab_spark.toPandas().set_index(f\"{cat_feature}_{target_feature}\")\n",
    "\n",
    "    # Run Chi-Square test\n",
    "    chi2, p, dof, expected = chi2_contingency(crosstab)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Chi-squared statistic: {chi2:.3f}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(f\"p-value: {p:.6f}\")\n",
    "\n",
    "    if p < 0.05:\n",
    "        print(\"-- Result: p-value < 0.05 ‚Üí Reject H‚ÇÄ\")\n",
    "        print(f\"‚Üí There is a statistically significant association between '{cat_feature}' and '{target_feature}'.\")\n",
    "    else:\n",
    "        print(\"-- Result: p-value ‚â• 0.05 ‚Üí Fail to reject H‚ÇÄ\")\n",
    "        print(f\"‚Üí No statistically significant association between '{cat_feature}' and '{target_feature}'.\")\n",
    "\n",
    "    # Optional expected frequencies\n",
    "    if show_expected:\n",
    "        print(\"\\nüìä Expected Frequencies:\")\n",
    "        print(pd.DataFrame(expected, index=crosstab.index, columns=crosstab.columns))\n",
    "\n",
    "    # Optional residuals heatmap\n",
    "    if show_residuals:\n",
    "        residuals = (crosstab - expected) / np.sqrt(expected)\n",
    "        print(\"\\nStandardized Residuals:\")\n",
    "        print(residuals.round(2))\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "        sns.heatmap(residuals, annot=True, cmap=cmap, center=0, fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(f\"Standardized Residuals Heatmap: {cat_feature} vs {target_feature}\", fontsize=14, weight=\"bold\", pad=20)\n",
    "        plt.ylabel(cat_feature)\n",
    "        plt.xlabel(target_feature)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def cal_levene(dataframe, categorical_feature, num_feature, center=\"mean\"):\n",
    "    \"\"\"\n",
    "    Perform Levene‚Äôs test to assess the equality (homogeneity) of variances \n",
    "    for a numeric feature across two or more groups defined by a categorical feature.\n",
    "\n",
    "    Levene's test is used to verify the assumption of equal variances \n",
    "    (homoscedasticity), which is important for parametric tests such as the \n",
    "    independent t-test and ANOVA.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pd.DataFrame\n",
    "        The input DataFrame containing the features to test.\n",
    "\n",
    "    categorical_feature : str\n",
    "        The name of the categorical column that defines the grouping.\n",
    "\n",
    "    num_feature : str\n",
    "        The name of the numerical column whose variance is being compared across groups.\n",
    "\n",
    "    center : str, optional (default=\"mean\")\n",
    "        Specifies the measure of central tendency to use when calculating deviations:\n",
    "        - \"mean\": classic Levene's test (sensitive to non-normal data)\n",
    "        - \"median\": more robust to non-normal distributions (Brown‚ÄìForsythe test)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the Levene test statistic, p-value, and an interpretation of whether \n",
    "        the variances are equal or significantly different.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - H‚ÇÄ (Null Hypothesis): All groups have equal variances.\n",
    "    - H‚ÇÅ (Alternative Hypothesis): At least one group has different variance.\n",
    "    - If p > 0.05 ‚Üí Fail to reject H‚ÇÄ ‚Üí Variances are approximately equal.\n",
    "    - If p ‚â§ 0.05 ‚Üí Reject H‚ÇÄ ‚Üí Variances are significantly different (heteroscedasticity).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html\n",
    "    - https://www.geeksforgeeks.org/levenes-test-in-python/\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"üîç Levene‚Äôs test: {num_feature} ~ {categorical_feature}\")\n",
    "    # Extract unique group labels\n",
    "    groups = dataframe[categorical_feature].unique()    \n",
    "    # Create a list of values for each group\n",
    "    data_groups = [dataframe[dataframe[categorical_feature] == g][num_feature] for g in groups]    \n",
    "    # Perform Levene‚Äôs test\n",
    "    stat, p = levene(*data_groups, center=center)\n",
    "    \n",
    "    print(f\"Levene statistic: {stat:.3f}\")\n",
    "    print(f\"p-value: {p}\")\n",
    "    if p > 0.05:\n",
    "        print(\"üü¢ Variances are approximately equal across groups.\")\n",
    "    else:\n",
    "        print(\"‚ö™ Variances are significantly different across groups.\")\n",
    "\n",
    "def cal_mannwhitneyu(dataframe, categorical_feature, num_feature):\n",
    "    \"\"\"\n",
    "    Perform the Mann‚ÄìWhitney U test (Wilcoxon rank-sum test) to assess whether there \n",
    "    is a statistically significant difference in the distribution of a numerical feature \n",
    "    between two independent groups defined by a binary categorical feature.\n",
    "\n",
    "    The function also compares medians, calculates the effect size (r), provides interpretation,\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : pd.DataFrame\n",
    "        The input DataFrame containing the data.\n",
    "\n",
    "    categorical_feature : str\n",
    "        Column name of the categorical feature (must contain exactly 2 unique values).\n",
    "\n",
    "    num_feature : str\n",
    "        Column name of the numerical feature to compare.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the U statistic, p-value, medians, Z-score, effect size r, and interpretation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - H‚ÇÄ (Null Hypothesis): The two groups have the same distribution.\n",
    "    - H‚ÇÅ (Alternative Hypothesis): The distributions are different.\n",
    "    - If p ‚â§ 0.05 ‚Üí reject H‚ÇÄ ‚Üí significant difference.\n",
    "    - Effect size r helps interpret how strong the difference is:\n",
    "        * Small ~0.1, Medium ~0.3, Large ‚â•0.5\n",
    "    \"\"\"\n",
    "\n",
    "    groups = dataframe[categorical_feature].dropna().unique()\n",
    "\n",
    "    if len(groups) != 2:\n",
    "        print(f\"‚ùå Error: Mann-Whitney U test requires exactly 2 groups, but found {len(groups)}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Mann‚ÄìWhitney U Test for '{num_feature}' by '{categorical_feature}'\\n\")\n",
    "    print(\"H‚ÇÄ: The distributions of the two groups are equal.\")\n",
    "    print(\"H‚ÇÅ: The distributions are different.\\n\")\n",
    "\n",
    "    group1 = dataframe[dataframe[categorical_feature] == groups[0]][num_feature].dropna()\n",
    "    group2 = dataframe[dataframe[categorical_feature] == groups[1]][num_feature].dropna()\n",
    "\n",
    "    stat, p = mannwhitneyu(group1, group2, alternative=\"two-sided\")\n",
    "\n",
    "    print(f\"U statistic : {stat}\")\n",
    "    print(f\"p-value     : {p}\")\n",
    "\n",
    "    # Interpretation\n",
    "    if p <= 0.05:\n",
    "        print(\"\\n‚úÖ Result: Statistically significant difference between the two groups (Reject H‚ÇÄ).\")\n",
    "        median1 = group1.median()\n",
    "        median2 = group2.median()\n",
    "        if median1 > median2:\n",
    "            print(f\" Interpretation: Group '{groups[0]}' has a higher median '{num_feature}' than Group '{groups[1]}'.\")\n",
    "        elif median1 < median2:\n",
    "            print(f\" Interpretation: Group '{groups[1]}' has a higher median '{num_feature}' than Group '{groups[0]}'.\")\n",
    "        else:\n",
    "            print(\" Interpretation: The medians are equal, but distributions may still differ.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö™ Result: No statistically significant difference between the two groups (Fail to reject H‚ÇÄ).\")\n",
    "\n",
    "\n",
    "def t_test_with_cohens_d(data, categorical_feature, num_feature, equal_var = False):\n",
    "    \"\"\"\n",
    "    Perform an Independent Two-Sample T-Test and compute Cohen's d to evaluate \n",
    "    the difference between two independent groups on a numeric variable.\n",
    "\n",
    "    This function tests whether the means of two independent groups are statistically different,\n",
    "    and also calculates the magnitude of the difference (effect size) using Cohen's d.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input DataFrame containing the categorical and numerical features.\n",
    "\n",
    "    categorical_feature : str\n",
    "        The name of the categorical column used to define the two groups (must have exactly 2 unique values).\n",
    "\n",
    "    num_feature : str\n",
    "        The name of the numerical feature to compare between the two groups.\n",
    "\n",
    "    equal_var : bool, optional (default=False)\n",
    "        Assumes equal population variance if True (Student‚Äôs t-test). If False (default), performs Welch‚Äôs t-test.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the t-statistic, p-value, Cohen‚Äôs d, and interpretation of the effect size.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - H‚ÇÄ (null hypothesis): The two groups have equal means.\n",
    "    - H‚ÇÅ (alternative): The means are significantly different.\n",
    "    - Cohen's d interpretation:\n",
    "        - 0.2  ‚Üí small effect\n",
    "        - 0.5  ‚Üí medium effect\n",
    "        - 0.8+ ‚Üí large effect\n",
    "    - Welch‚Äôs t-test is recommended when group variances are unequal (default setting).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - https://www.scribbr.com/statistics/t-test/\n",
    "    - https://en.wikipedia.org/wiki/Cohen%27s_d\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract unique groups\n",
    "    groups = data[categorical_feature].dropna().unique()\n",
    "\n",
    "    if len(groups) > 2:\n",
    "        print(f\"‚ùå Error: Independent T-Test requires 2 groups.\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"üîç Independent T-Test: {num_feature} ~ {categorical_feature}\")\n",
    "        # Extract values\n",
    "        x1 = data[data[categorical_feature] == groups[0]][num_feature].dropna()\n",
    "        x2 = data[data[categorical_feature] == groups[1]][num_feature].dropna()\n",
    "\n",
    "        # T-test (independent)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=equal_var)  # Welch‚Äôs t-test if variances may differ\n",
    "\n",
    "        # Calculate Cohen‚Äôs d\n",
    "        nx1, nx2 = len(x1), len(x2)\n",
    "        pooled_std = np.sqrt(((nx1 - 1)*np.var(x1, ddof=1) + (nx2 - 1)*np.var(x2, ddof=1)) / (nx1 + nx2 - 2))\n",
    "        cohens_d = (np.mean(x1) - np.mean(x2)) / pooled_std\n",
    "\n",
    "        # Output\n",
    "        print(f\"\\nüîç T-Test between group'{groups[0]}' and group '{groups[1]}':\")\n",
    "        print(f\"t-statistic: {t_stat:.3f}\")\n",
    "        print(f\"p-value: {p_value:.6f}\")\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(\"\\n‚úÖ Significant difference found (p < 0.05)\")\n",
    "            print(f\"\\nüìè Cohen's d: {cohens_d:.3f}\")            \n",
    "            # Interpretation of Cohen's d\n",
    "            if abs(cohens_d) < 0.2:\n",
    "                size = \"small\"\n",
    "            elif abs(cohens_d) < 0.5:\n",
    "                size = \"medium\"\n",
    "            else:\n",
    "                size = \"large\"\n",
    "            print(f\"üß† Effect size interpretation: {size} effect\")\n",
    "        else:\n",
    "            print(\"\\n‚ÑπÔ∏è No significant difference found (p >= 0.05)\")\n",
    "\n",
    "def perform_anova_with_tukey(df, numeric_feature, categorical_feature, typ=2):\n",
    "    \"\"\"\n",
    "    Perform a One-Way ANOVA test to determine whether there are statistically \n",
    "    significant differences between the means of three or more independent groups. \n",
    "\n",
    "    If the ANOVA test is significant (p < 0.05), Tukey's HSD post-hoc test is performed\n",
    "    to identify which specific pairs of groups differ from each other.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataset containing the numeric and categorical features.\n",
    "\n",
    "    numeric_feature : str\n",
    "        The name of the numerical (continuous) response variable.\n",
    "\n",
    "    categorical_feature : str\n",
    "        The name of the categorical (independent) variable used to group the data.\n",
    "\n",
    "    typ : int, optional (default=2)\n",
    "        The type of sum of squares to use in the ANOVA test:\n",
    "        - Type I (1): Sequential.\n",
    "        - Type II (2): Default and commonly used for balanced designs.\n",
    "        - Type III (3): Use when model includes interaction terms or unbalanced data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the ANOVA table, p-value, interpretation, and (if significant) the Tukey HSD test summary.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - H‚ÇÄ (null hypothesis): All group means are equal.\n",
    "    - H‚ÇÅ (alternative hypothesis): At least one group mean is different.\n",
    "    - If p < 0.05 ‚Üí reject H‚ÇÄ ‚Üí perform Tukey‚Äôs HSD to find which groups differ.\n",
    "    - Assumptions:\n",
    "        1. Independence of observations\n",
    "        2. Normally distributed groups (Shapiro or Anderson test can check this)\n",
    "        3. Homogeneity of variances (Levene's test)\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - https://www.scribbr.com/statistics/one-way-anova/\n",
    "    - https://en.wikipedia.org/wiki/Analysis_of_variance\n",
    "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tukey_hsd.html\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract unique groups\n",
    "    groups = df[categorical_feature].dropna().unique()\n",
    "    \n",
    "    if len(groups) < 3:\n",
    "        print(f\"‚ùå Error: ANOVA requires 3 or more groups.\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"\\nüîç ANOVA Test: {numeric_feature} ~ {categorical_feature} (Type {typ})\")\n",
    "\n",
    "        # Fit OLS model\n",
    "        model = ols(f\"{numeric_feature} ~ C({categorical_feature})\", data=df).fit()\n",
    "\n",
    "        # Perform ANOVA\n",
    "        anova_table = anova_lm(model, typ=typ)\n",
    "        print(\"\\nüìä ANOVA Table:\")\n",
    "        print(anova_table)\n",
    "\n",
    "        # Extract p-value\n",
    "        p_value = anova_table[\"PR(>F)\"].iloc[0]\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(\"\\n‚úÖ Significant difference found (p < 0.05)\")\n",
    "            print(\"‚û°Ô∏è Performing Tukey's HSD post-hoc test:\")\n",
    "\n",
    "            tukey = pairwise_tukeyhsd(df[numeric_feature], df[categorical_feature])\n",
    "            print(tukey.summary())\n",
    "        else:\n",
    "            print(\"\\n‚ÑπÔ∏è No significant difference found (p >= 0.05)\")\n",
    "\n",
    "def perform_kruskal_test(df, categorical_feature, numeric_feature):\n",
    "    \"\"\"\n",
    "    Perform the Kruskal-Wallis H-test to determine whether there are statistically \n",
    "    significant differences in the distribution of a numeric variable across \n",
    "    three or more independent groups.\n",
    "\n",
    "    If the result is significant (p < 0.05), Dunn's post-hoc test with Bonferroni correction \n",
    "    is performed to identify which group pairs differ.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input dataset containing the categorical and numerical variables.\n",
    "\n",
    "    categorical_feature : str\n",
    "        The name of the categorical feature that defines the groups.\n",
    "\n",
    "    numeric_feature : str\n",
    "        The name of the numeric feature to be compared across groups.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the Kruskal-Wallis H-statistic, p-value, interpretation, and \n",
    "        optionally the results of Dunn's post-hoc test.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - H‚ÇÄ (null hypothesis): The distribution of the numeric variable is the same across all groups.\n",
    "    - H‚ÇÅ (alternative hypothesis): At least one group has a different distribution.\n",
    "    - If p < 0.05 ‚Üí reject H‚ÇÄ ‚Üí use Dunn‚Äôs test to explore specific group differences.\n",
    "    - Kruskal-Wallis is a non-parametric alternative to one-way ANOVA.\n",
    "    - It does not assume normality, but assumes:\n",
    "        1. Independent samples\n",
    "        2. Ordinal or continuous response variable\n",
    "        3. Similar shapes of distributions\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    - `scipy.stats.kruskal`\n",
    "    - `scikit-posthocs` package for Dunn‚Äôs test (`import scikit_posthocs as sp`)\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - https://www.geeksforgeeks.org/kruskal-wallis-test/\n",
    "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html\n",
    "    - https://scikit-posthocs.readthedocs.io/en/latest/index.html\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract values\n",
    "    groups = df[categorical_feature].dropna().unique()\n",
    "    if len(groups) < 3:\n",
    "        print(f\"‚ùå Error: Kruskal-Wallis H-test requires 3 or more groups.\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"\\nüîç Kruskal-Wallis Test: {numeric_feature} ~ {categorical_feature}\")\n",
    "        data_groups = [df[df[categorical_feature] == g][numeric_feature].dropna() for g in groups]\n",
    "\n",
    "        # Perform kruskal\n",
    "        stat, p = kruskal(*data_groups)\n",
    "\n",
    "        print(f\"Kruskal-Wallis H-statistic: {stat:.3f}\")\n",
    "        print(f\"p-value: {p}\")\n",
    "        \n",
    "        if p < 0.05:\n",
    "            print(\"üü¢ Significant difference found. Running Dunn's Post-Hoc Test...\")\n",
    "            dunn_result = sp.posthoc_dunn(df, val_col=numeric_feature, group_col=categorical_feature, p_adjust=\"bonferroni\")\n",
    "            print(dunn_result)\n",
    "        else:\n",
    "            print(\"\\n‚ÑπÔ∏è No significant difference found (p >= 0.05)\")\n",
    "\n",
    "def cal_normaltest(cat_feature, num_feature, df):\n",
    "    \"\"\"\n",
    "    Perform D‚ÄôAgostino and Pearson‚Äôs normality test on a numerical feature \n",
    "    across groups defined by a categorical feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cat_feature : str\n",
    "        The name of the categorical column that defines the groups.\n",
    "\n",
    "    num_feature : str\n",
    "        The name of the numerical column to test for normality.\n",
    "\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints the test statistic and p-value for each group.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - H‚ÇÄ (null hypothesis): The data is normally distributed.\n",
    "    - H‚ÇÅ (alternative): The data is not normally distributed.\n",
    "    - If p > 0.05 ‚Üí fail to reject H‚ÇÄ ‚Üí data appears normal.\n",
    "    - If p ‚â§ 0.05 ‚Üí reject H‚ÇÄ ‚Üí data likely not normal.\n",
    "    - Recommended for n ‚â• 20, especially reliable for n > 50.\n",
    "    - Requires at least 8 non-null values per group (as per scipy recommendation).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîé D‚ÄôAgostino and Pearson Normality Test for '{num_feature}' across '{cat_feature}' groups\\n\")\n",
    "\n",
    "    for group in df[cat_feature].dropna().unique():\n",
    "        data = df[df[cat_feature] == group][num_feature].dropna()\n",
    "        n = len(data)\n",
    "\n",
    "        print(f\" Group: {group} (n = {n})\")\n",
    "        \n",
    "        if n < 8:\n",
    "            print(f\"‚ö†Ô∏è Too few observations (< 8) to perform the test.\\n\")\n",
    "            continue\n",
    "\n",
    "        stat, p = normaltest(data)\n",
    "\n",
    "        print(f\"  Statistic : {stat:.3f}\")\n",
    "        print(f\"  p-value   : {p:.5f}\")\n",
    "        \n",
    "        if p > 0.05:\n",
    "            print(f\"  üü¢ Interpretation: Data appears to follow a normal distribution.\\n\")\n",
    "        else:\n",
    "            print(f\"  üî¥ Interpretation: Data does not appear to follow a normal distribution.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081eb8cd",
   "metadata": {},
   "source": [
    "##  Attrition Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_Distribution  = df_customer_churn[\"Attrition_Flag\"].value_counts().loc[[\"Attrited Customer\", \"Existing Customer\"]]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=False, figsize=(15, 5))\n",
    "# ax[0]\n",
    "ax[0].pie(\n",
    "    attrition_Distribution,\n",
    "    labels = [\"Attrited Customer\", \"Existing Customer\"],\n",
    "    colors = color(n_colors=2),\n",
    "    autopct = \"%1.2f%%\",\n",
    "    startangle = 150,\n",
    "    explode = (0, 0.08),\n",
    "    shadow= True\n",
    ")\n",
    "ax[0].set_title(\"Attrition Distribution\", weight=\"bold\", fontsize=14, pad=25)\n",
    "\n",
    "# ax[1]\n",
    "sns.countplot(data=df_customer_churn, x = \"Attrition_Flag\", palette=color(n_colors=2), ax=ax[1])\n",
    "ax[1].set_title(\"Count plot of Attrition Distribution\", weight=\"bold\", fontsize=14, pad=25)\n",
    "for container in ax[1].containers:\n",
    "    ax[1].bar_label(container, fmt=\"%d\", label_type=\"edge\", fontsize=10, weight=\"bold\")\n",
    "ax[1].set_ylabel(\"Number of Customer\")\n",
    "sns.despine(ax=ax[1], top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c25b3f",
   "metadata": {},
   "source": [
    "**Insights:** <br>\n",
    "- Around `16.07%` customers has attrited, which reflects a realistic churn rate in the banking sector.\n",
    "- Although the data is imbalanced, it is not incorrect ‚Äî it naturally reflects actual customer behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a5600",
   "metadata": {},
   "source": [
    "## Numerical Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical_features(df=df_customer_churn, numerical_features = num_features):\n",
    "    fig, axes = plt.subplots(len(numerical_features), 2, figsize=(12, len(numerical_features)*4))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    for i, feature in enumerate(numerical_features):\n",
    "        sns.histplot(data=df[feature], color=\"#7CAE00\", bins = 20, kde=True, ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"Histogram of {feature}\")\n",
    "        axes[i, 0].set_ylabel(\"\")\n",
    "        axes[i, 0].grid(color=\"gray\", linestyle=\":\", linewidth=0.7)\n",
    "        axes[i, 0].axvline(df[feature].median(), color=\"blue\", linestyle=\"--\", label=\"Median Train\")\n",
    "\n",
    "        sns.boxplot(data=df[feature], color=\"#00BFC4\", orient=\"h\", ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"Horizontal Violin plot of {feature}\")\n",
    "        axes[i, 1].set_xlabel(feature)\n",
    "        axes[i, 1].grid(color=\"gray\", linestyle=\":\", linewidth=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_numerical_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skewness(data = df_customer_churn, numerical_features = num_features, highlight=True, sort=True):\n",
    "    skewness_dict = {}\n",
    "    skew_feature = []\n",
    "    for feature in numerical_features:\n",
    "        skew = data[feature].skew(skipna=True)\n",
    "        skewness_dict[feature] = skew\n",
    "\n",
    "    skew_df = pd.DataFrame.from_dict(skewness_dict, orient=\"index\", columns=[\"Skewness\"])\n",
    "    if sort:\n",
    "        skew_df = skew_df.reindex(skew_df[\"Skewness\"].abs().sort_values(ascending=False).index)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    print(f\"\\nüîç Skewness for dataset:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Feature':<30} | {'Skewness':<10} | {'Remark'}\")\n",
    "    print(\"-\"*70)\n",
    "    for feature, row in skew_df.iterrows():\n",
    "        skew = row[\"Skewness\"]\n",
    "        abs_skew = abs(skew)\n",
    "        if abs_skew > 1:\n",
    "            remark = \"Highly skewed\"\n",
    "            color = \"\\033[91m\"  \n",
    "        elif abs_skew > 0.5:\n",
    "            remark = \"Moderately skewed\"\n",
    "            color = \"\\033[93m\"  \n",
    "        else:\n",
    "            remark = \"Approximately symmetric\"\n",
    "            color = \"\"\n",
    "        endc = \"\\033[0m\" if color else \"\"\n",
    "        if highlight and color:\n",
    "            print(f\"{color}{feature:<30} | {skew:>+10f} | {remark}{endc}\")\n",
    "            skew_feature.append(feature)\n",
    "        else:\n",
    "            print(f\"{feature:<30} | {skew:>+10f} | {remark}\")\n",
    "    print(\"-\"*70)\n",
    "    return skew_feature, skew_df\n",
    "\n",
    "skew_feature, skew_df = check_skewness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824326a",
   "metadata": {},
   "source": [
    "### Insights on Numerical Feature Distributions\n",
    "\n",
    "**Shape and Spread of Distributions**\n",
    "\n",
    "- **Histograms** reveal that all features are distributed fairly evenly across their respective ranges.\n",
    "- **Box plot** confirm that the central 50% of values (the interquartile range), and the whiskers (showing the range).\n",
    "\n",
    "**Skewness Analysis**\n",
    "\n",
    "- The **skewness values** for numerical features (`Total_Trans_Ct`, `Months_on_book`, `Customer_Age` and `Total_Revolving_Bal`) in dataset are less than 0.5, indicating that the distributions are **approximately symmetric**. which means:\n",
    "\n",
    "- The features: `Total_Ct_Chng_Q4_Q1`, `Total_Trans_Amt`, `Total_Amt_Chng_Q4_Q1`, `Credit_Limit`, `Avg_Open_To_Buy`, `Avg_Utilization_Ratio`  have **skewness values** greater than 0.5, indicating that the distributions are **Highly/Moderately symmetric**. Many model assumes **normal distribution** but in reality data points may not be perfectly symmetric. If the data are skewed, then this kind of model will always underestimate the skewness risk.The more the data is skewed the less accurate the model will be. We need to handle skewness in chapter **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc6580",
   "metadata": {},
   "source": [
    "### Correlation Analysis of Numerical Features\n",
    "\n",
    "1. **What is Correlation?**\n",
    "\n",
    "**Correlation** measures the **strength and direction of a linear relationship** between two variables.\n",
    "\n",
    "* The correlation coefficient (usually denoted as **r**) ranges from **-1 to 1**.\n",
    "\n",
    "2. **Interpretation of Correlation Values**\n",
    "\n",
    "| Value of r | Relationship Type           | Interpretation                               |\n",
    "| ---------- | --------------------------- | -------------------------------------------- |\n",
    "| `r ‚âà 1`    | Strong positive correlation | As X increases, Y also increases linearly    |\n",
    "| `r ‚âà -1`   | Strong negative correlation | As X increases, Y decreases linearly         |\n",
    "| `r ‚âà 0`    | No linear correlation       | No clear linear relationship between X and Y |\n",
    "\n",
    "**Common interpretation of |r|**\n",
    "\n",
    "![](https://i.ibb.co/TQ3FbQK/correlation.png)\n",
    "\n",
    "3. **Pearson Correlation Formula**\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2 \\cdot \\sum (y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "* $x_i, y_i$: observed values\n",
    "* $\\bar{x}, \\bar{y}$: sample means of X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd99640",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_customer_churn.drop(columns=\"CLIENTNUM\", axis=1).corr(numeric_only=True)\n",
    "# one_like can build a matrix of boolean(True, False) with the same shape as our data\n",
    "ones_corr = np.ones_like(corr_matrix, dtype=bool)\n",
    "mask = np.triu(ones_corr)\n",
    "adjusted_mask = mask[1:, :-1]\n",
    "adjusted_cereal_corr = corr_matrix.iloc[1:, :-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 9))\n",
    "# That method uses HUSL colors, so you need hue, saturation, and lightness. \n",
    "# I used hsluv.org to select the colors of this chart.\n",
    "cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data=adjusted_cereal_corr, mask=adjusted_mask,\n",
    "            annot=True, fmt=\".2f\", cmap=cmap,\n",
    "            vmin=-1, vmax=1, linecolor=\"white\", linewidths=0.5)\n",
    "\n",
    "title = \"CORRELATION MATRIX COMPOSITION\\n\"\n",
    "ax.set_title(title, loc=\"left\", fontsize=18, weight=\"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a35701",
   "metadata": {},
   "source": [
    "## **Insights from Correlation Analysis of Numerical Features**\n",
    "\n",
    "**1. Overall Weak Correlation Pattern**\n",
    "\n",
    "* Most numerical features exhibit **correlation coefficients near 0**.\n",
    "* Indicates **minimal linear dependency** among feature pairs.\n",
    "\n",
    "> **Implication**: No sign of multicollinearity ‚Üí suitable for models that assume feature independence (e.g., **Logistic Regression**) as well as **tree-based models** (e.g., RandomForest, XGBoost).\n",
    "\n",
    "**2. Notable Positive Correlations**\n",
    "\n",
    "| Feature Pair                                    | Correlation | Interpretation                                                                        |\n",
    "| ----------------------------------------------- | ----------- | ------------------------------------------------------------------------------------- |\n",
    "| `Total_Trans_Ct` & `Total_Trans_Amt`            | **0.81**    | Higher transaction count usually corresponds to higher transaction amounts.           |\n",
    "| `Months_on_book` & `Customer_Age`               | **0.79**    | Older customers tend to have longer banking relationships.                            |\n",
    "| `Total_Ct_Chng_Q4_Q1` & `Total_Amt_Chng_Q4_Q1`  | **0.38**    | Changes in transaction frequency moderately align with changes in transaction amount. |\n",
    "| `Avg_Utilization_Ratio` & `Total_Revolving_Bal` | **0.62**    | Customers with high utilization tend to carry larger revolving balances.              |\n",
    "\n",
    "**3. Moderate Negative Correlations**\n",
    "\n",
    "| Feature Pair                                | Correlation | Interpretation                                                             |\n",
    "| ------------------------------------------- | ----------- | -------------------------------------------------------------------------- |\n",
    "| `Avg_Utilization_Ratio` & `Avg_Open_To_Buy` | **-0.54**   | Higher utilization reduces available credit ‚Üí inverse relationship.        |\n",
    "| `Avg_Utilization_Ratio` & `Credit_Limit`    | **-0.48**   | Customers with higher credit limits generally use a smaller portion of it. |\n",
    "\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Observation                                     | Actionable Insight                                       |\n",
    "| ----------------------------------------------- | -------------------------------------------------------- |\n",
    "| Weak overall correlations                       | Features are not redundant ‚Üí preserve full feature set   |\n",
    "| Strong link: `Trans_Ct` ‚Üî `Trans_Amt`           | Confirms purchase frequency correlates with volume       |\n",
    "| `Avg_Utilization_Ratio` as behavioral indicator | Valuable signal for **credit risk and churn prediction** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02216392",
   "metadata": {},
   "source": [
    "## Categorical Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(df, cat_features):\n",
    "    fig, ax = plt.subplots(len(cat_features), 2, figsize=(14, len(cat_features)*4))\n",
    "    ax = np.atleast_2d(ax)\n",
    "\n",
    "    for i, feature in enumerate(cat_features):\n",
    "        # ----------------------------\n",
    "        # LEFT: Vertical Countplot\n",
    "        # ----------------------------\n",
    "        sns.countplot(data=df, x=feature, ax=ax[i, 0],\n",
    "                      palette=color(n_colors=len(df[feature].unique())))\n",
    "        \n",
    "        ax[i, 0].set_title(f\"Count of {feature}\", fontsize=14, pad=15, weight=\"bold\")\n",
    "        ax[i, 0].set_xlabel(feature)\n",
    "        if feature == \"Education_Level\":\n",
    "            ax[i, 0].set_xticklabels(labels = ax[i, 0].get_xticklabels(), rotation = 45)\n",
    "        ax[i, 0].set_ylabel(\"\")\n",
    "        sns.despine(ax=ax[i, 0], top=True, right=True)\n",
    "\n",
    "        # Add count labels on top\n",
    "        for p in ax[i, 0].patches:\n",
    "            height = p.get_height()\n",
    "            x = p.get_x() + p.get_width() / 2\n",
    "            ax[i, 0].text(x, height + max(df[feature].value_counts()) * 0.01,\n",
    "                          f\"{int(height)}\",\n",
    "                          ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "        # ----------------------------\n",
    "        # RIGHT: Barplot with % labels\n",
    "        # ----------------------------\n",
    "        feature_counts = df[feature].value_counts(normalize=True).sort_index()\n",
    "        percentage_df = feature_counts.mul(100).round(2).reset_index()\n",
    "        percentage_df.columns = [feature, \"Percentage\"]\n",
    "\n",
    "        sns.barplot(data=percentage_df, x=feature, y=\"Percentage\",\n",
    "                    ax=ax[i, 1],\n",
    "                    palette=color(n_colors=len(feature_counts)))\n",
    "        \n",
    "        ax[i, 1].set_title(f\"Percentage of {feature}\", fontsize=14, pad=15, weight=\"bold\")\n",
    "        ax[i, 1].set_ylabel(\"Percentage (%)\")\n",
    "        if feature == \"Education_Level\":\n",
    "            ax[i, 1].set_xticklabels(labels = ax[i, 1].get_xticklabels(), rotation = 45)\n",
    "        ax[i, 1].set_xlabel(feature)\n",
    "        sns.despine(ax=ax[i, 1], top=True, right=True)\n",
    "\n",
    "        # Add % labels on top\n",
    "        for p in ax[i, 1].patches:\n",
    "            height = p.get_height()\n",
    "            x = p.get_x() + p.get_width() / 2\n",
    "            ax[i, 1].text(x, height + 0.5,\n",
    "                          f\"{height:.1f}%\",\n",
    "                          ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cat_features.remove(\"Attrition_Flag\")\n",
    "plot_categorical_distribution(df=df_customer_churn, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a6e93",
   "metadata": {},
   "source": [
    "**Categorical Feature Distribution**\n",
    "\n",
    "**1. Attrition Flag (Target Variable)**\n",
    "\n",
    "* **Existing Customers** account for **83.9%** ‚Üí the dataset is clearly **imbalanced**.\n",
    "* ‚Üí Apply techniques like **SMOTE**, **class weights**, or **threshold tuning**.\n",
    "\n",
    "**2. Gender**\n",
    "\n",
    "* Nearly balanced: **Female (52.9%)**, **Male (47.1%)**.\n",
    "* ‚Üí No special handling required.\n",
    "\n",
    "**3. Education Level**\n",
    "\n",
    "* **Graduate (30.9%)** and **Uneducated (24.7%)** dominate.\n",
    "* **Doctorate** and **Post-Graduate** are rare (<10%) ‚Üí consider grouping.\n",
    "* **Unknown = 15.0%** ‚Üí retained and captured via `is_unknown_education_level`.\n",
    "\n",
    "**4. Marital Status**\n",
    "\n",
    "* **Married** customers dominate (**46.3%**) ‚Üí indicates stable demographic.\n",
    "* **Unknown = 7.4%** ‚Üí retained or grouped; already represented by `is_unknown_marital_status`.\n",
    "\n",
    "**5. Income Category**\n",
    "\n",
    "* Most customers earn **less than \\$40K (35.2%)**.\n",
    "* High-income group (`> \\$120K`) only **7.2%** ‚Üí can be grouped as `\"High income\"`.\n",
    "* **Unknown = 11.0%** ‚Üí potentially meaningful ‚Üí tracked via `is_unknown_income_category`.\n",
    "\n",
    "**6. Card Category**\n",
    "\n",
    "* **Blue cards** dominate (**93.2%**); other types are rare.\n",
    "* ‚Üí Recommend grouping into `\"Blue\"` vs `\"Other\"` to simplify modeling.\n",
    "\n",
    "**7. Dependent Count**\n",
    "\n",
    "* Most customers have **1‚Äì3 dependents**.\n",
    "* Very few have 5 ‚Üí consider grouping `\"4+\"`.\n",
    "\n",
    "**8. Months Inactive (Last 12 Months)**\n",
    "\n",
    "* Inactivity mainly spans **2‚Äì3 months** ‚Üí generally stable.\n",
    "* Very few customers are inactive for more than 4 months.\n",
    "\n",
    "**9. Contact Count (Last 12 Months)**\n",
    "\n",
    "* **2‚Äì3 contacts/year** is most common (**\\~65%**).\n",
    "* Customers with **0‚Äì1 contact** may be **disengaged or at risk** ‚Üí investigate churn link.\n",
    "\n",
    "**10. Total Relationship Count**\n",
    "\n",
    "* Fairly even spread across 2‚Äì6 products.\n",
    "* Only **9%** have just 1 relationship ‚Üí possibly at higher churn risk.\n",
    "\n",
    "**Summary & Recommended Actions**\n",
    "\n",
    "| Observation                               | Suggested Action                                            |\n",
    "| ----------------------------------------- | ----------------------------------------------------------- |\n",
    "| Target imbalance (`Attrition_Flag`)       | Use **SMOTE**, **class weighting**, or **threshold tuning** |\n",
    "| Skewed category distributions             | **Group rare levels** to improve model stability            |\n",
    "| \"Unknown\" values in categorical features  | Keep \"Unknown\" values.                                      |\n",
    "| Behavioral indicators (e.g., low contact) | Investigate as **potential churn predictors**               |\n",
    "| All categorical features                  | Ready for **One-hot or Ordinal Encoding**                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91875437",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "# defining function for plotting\n",
    "def bivariate_percent_plot(cat, df, figsize=(15, 6), order = None, rot = 0):\n",
    "    \n",
    "    display(HTML(f\"<h2 style='text-align:center; font-size:22px; color:blue;'><b>Distribution of {cat} by Attrition_Flag</b></h2>\"))\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=False, figsize=figsize)\n",
    "    # Plot 1\n",
    "    # Calculate the total number of each \"cat\" by Attrition_Flag\n",
    "    grouped = df.groupby([cat, \"Attrition_Flag\"]).size().unstack(fill_value=0)\n",
    "    # Calculate the percentages\n",
    "    percentages = grouped.div(grouped.sum(axis=1), axis=0) * 100\n",
    "    if order is not None:\n",
    "        percentages = percentages.loc[order]\n",
    "        labels = order\n",
    "    else:\n",
    "        labels = percentages.index\n",
    "\n",
    "    # That method uses HUSL colors, so you need hue, saturation, and lightness. \n",
    "    # I used hsluv.org to select the colors of this chart.\n",
    "    cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "    # Draw stacked bar plot\n",
    "    ax[0] = percentages.plot(kind=\"bar\", stacked=True, cmap=cmap, ax = ax[0], use_index=True)\n",
    "    for container in ax[0].containers:\n",
    "        ax[0].bar_label(container, fmt='%1.0f%%', label_type=\"center\", weight=\"bold\", fontsize=10)\n",
    "\n",
    "    ax[0].set_title(f\"Percentage of Attrition by {cat}\", fontsize=14, weight=\"bold\")\n",
    "    ax[0].set_xlabel(f\"{cat}\", fontsize=12)\n",
    "    ax[0].set_ylabel(\"% Attrition Rate\", fontsize=12)\n",
    "    if cat in  [\"Education_Level\", \"Income_Category\"]:\n",
    "        ax[0].set_xticklabels(labels = labels, rotation = 45)\n",
    "    else:\n",
    "        ax[0].set_xticklabels(labels = labels, rotation = rot)\n",
    "    ax[0].legend_.remove()\n",
    "    # ax[0].grid(color=\"gray\", linestyle=\":\", linewidth=0.7)\n",
    "    sns.despine(left=False, bottom=False, ax=ax[0])\n",
    "\n",
    "    # Plot 2\n",
    "    sns.countplot(data=df, hue = \"Attrition_Flag\", x = cat,\n",
    "                palette=color(n_colors=2), ax=ax[1], order=order)\n",
    "    # Show value for each bar.\n",
    "    for container in ax[1].containers:\n",
    "        ax[1].bar_label(container, fmt='%d', label_type=\"edge\", fontsize=10, weight=\"bold\")\n",
    "\n",
    "    ax[1].set_title(f\"Attrition by {cat}\", fontsize=14, weight=\"bold\")\n",
    "    ax[1].set_xlabel(f\"{cat}\", fontsize=12)\n",
    "    ax[1].set_ylabel(\"Number of Customer\", fontsize=12)\n",
    "    ax[1].legend(title=\"Attrition\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    if cat in  [\"Education_Level\", \"Income_Category\"]:\n",
    "        ax[1].set_xticklabels(labels = ax[1].get_xticklabels(), rotation = 45)\n",
    "    else:\n",
    "        ax[1].set_xticklabels(labels = ax[1].get_xticklabels(), rotation = rot)\n",
    "    # ax[1].grid(color=\"gray\", linestyle=\":\", linewidth=0.7)\n",
    "    sns.despine(left=False, bottom=False, ax=ax[1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    cal_ChiSquare(cat_feature=cat, target_feature=\"Attrition_Flag\", df=df, show_residuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_features:\n",
    "    bivariate_percent_plot(cat=feature, df= df_customer_churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edf1e9",
   "metadata": {},
   "source": [
    "### Insight for Categorical Features by Attrition\n",
    "\n",
    "**1. Gender**\n",
    "\n",
    "* Distribution is balanced: **Female (52.9%)**, **Male (47.1%)**\n",
    "* **Statistically significant association** with churn (p = 0.0002)\n",
    "* **Females are more likely to churn** (Residual = **+2.36**)\n",
    "* **Males are less likely to churn** (Residual = **‚Äì2.50**)\n",
    "* ‚Üí Gender is a **mild but meaningful predictor** of attrition.\n",
    "\n",
    "**2. Education_Level**\n",
    "\n",
    "* **No statistically significant association** with churn (p = 0.051)\n",
    "* However, Doctorate holders show unusually high churn (Residual = +2.65), though sample size is small.\n",
    "* ‚Üí Overall: Education is not a strong predictor of churn.\n",
    "\n",
    "**3. Marital_Status**\n",
    "\n",
    "* Most customers are **Married** or **Single**\n",
    "* **No statistically significant association** with churn (p = **0.1089** ‚â• 0.05)\n",
    "* Residuals show mild trends:\n",
    "  * **Single**: slight tendency to churn more (+1.37)\n",
    "  * **Married**: slightly more likely to stay (‚Äì1.60)\n",
    "* ‚Üí Overall: **Marital status is not a strong churn predictor**.\n",
    "\n",
    "**4. Income_Category**\n",
    "\n",
    "* **Statistically significant association** with churn (p = **0.025** < 0.05)\n",
    "* Insights from standardized residuals:\n",
    "  * **\\$60K‚Äì\\$80K** ‚Üí significantly **less likely to churn** (**‚Äì2.42**) ‚Üí *statistically meaningful*\n",
    "  * **< \\$40K** ‚Üí slightly **more likely to churn** (**+1.67**) ‚Üí *not statistically significant*\n",
    "* ‚Üí Income category is a **moderate churn predictor**, driven mainly by the \\$60K‚Äì\\$80K segment\n",
    "\n",
    "**5. Card_Category**\n",
    "\n",
    "* **No statistically significant association** with churn (p = **0.525** ‚â• 0.05)\n",
    "* Residuals show **no meaningful deviation** (all |z| < 2)\n",
    "  * **Platinum** and **Gold** slightly overrepresented among churned, but not statistically significant\n",
    "* ‚Üí **Card type is not a reliable predictor** of attrition.\n",
    "\n",
    "**6. Dependent_count**\n",
    "\n",
    "* Most attrition customers have **1 and 3 dependents**\n",
    "* **No statistically significant association** with churn (p = **0.091** ‚â• 0.05)\n",
    "* Standardized residuals:\n",
    "  * **3 dependents** ‚Üí slightly **overrepresented** among churned customers (**+2.06**) ‚Üí *significant*\n",
    "  * Other groups show weak/no pattern (|z| < 2)\n",
    "* ‚Üí **Overall: weak signal**, may reconsider after grouping or binning.\n",
    "\n",
    "**7. Months_Inactive_12_mon**\n",
    "\n",
    "* **Strong statistically significant association** with churn (Chi¬≤ = 396.5, p < 0.00001)\n",
    "* Standardized residuals reveal very clear patterns:\n",
    "  * **1 month inactive** ‚Üí strongly **negatively associated** with churn (**‚Äì13.66**)\n",
    "    ‚Üí customers inactive for only 1 month are **very unlikely to churn**\n",
    "  * **3‚Äì4 months inactive** ‚Üí strongly **positively associated** with churn\n",
    "    (**+8.37**, **+7.19**) ‚Üí these customers are **much more likely to churn**\n",
    "  * **0 month inactive** ‚Üí also higher attrition than expected (**+4.79**)\n",
    "* ‚Üí Inactivity is a **powerful behavioral signal** for predicting churn.\n",
    "\n",
    "**8. Contacts_Count_12_mon**\n",
    "\n",
    "* **Very strong statistical association** with churn (Chi¬≤ = 586.6, p < 0.00001)\n",
    "* Standardized residuals show a **very strong churn pattern**:\n",
    "  * **0‚Äì2 contacts/year** ‚Üí **much less churn than expected**\n",
    "    (Residual = ‚Äì8.56 at 1 contact) ‚Üí these customers are more **loyal**\n",
    "  * **Frequent contacts (4‚Äì6 times/year)** ‚Üí **more likely to churn than expected**\n",
    "  * **6 contacts/year** ‚Üí extremely **high churn signal** (Residual = **+15.39**)\n",
    "* ‚Üí Frequent contact may reflect **issues, dissatisfaction, or pre-churn behavior**.\n",
    "\n",
    "**9. Total_Relationship_Count**\n",
    "\n",
    "* **Strong statistical association** with churn (Chi¬≤ = 284.1, p < 0.00001)\n",
    "* Residuals indicate a **clear inverse relationship**:\n",
    "  * Customers with **fewer relationships (1‚Äì2)** ‚Üí **more likely to churn**\n",
    "    (Residuals = **+7.18**, **+10.35** at 1‚Äì2 products)\n",
    "  * Customers with **4‚Äì6 products** ‚Üí **less likely to churn**\n",
    "    (Residuals = **‚Äì4.69**, **‚Äì4.41**, **‚Äì5.99** respectively)\n",
    "* ‚Üí Total number of products is a **strong loyalty indicator** ‚Äî more products, lower churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statical_testing(feature, df = df_customer_churn, total_categories = 2, target_feature = \"Attrition_Flag\"):\n",
    "    cal_normaltest(cat_feature=target_feature, num_feature=feature, df=df)\n",
    "    if total_categories == 2:\n",
    "        cal_mannwhitneyu(dataframe=df, categorical_feature=target_feature, num_feature=feature)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def plot_numerical_distribution_by_Attrition(feature, df = df_customer_churn, target_feature = \"Attrition_Flag\", order = None):\n",
    "    \"\"\"\n",
    "    Performs statical testing for each groups (distribution by target_feature) by Mann-Whitney U test,... <br>\n",
    "    Draw violinplot and histogram to display the distribution for each groups of feature.\n",
    "    Parameters:\n",
    "        feature (str): The name of the column representing the numerical variable.\n",
    "        df (pd.DataFrame): The input dataset.\n",
    "        target_feature (str): The name of the column representing the target feature.\n",
    "        order (list): Order items in plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    display(HTML(f\"<h2 style='text-align:center; font-size:22px; color:blue;'><b>Distribution of {feature} by Attrition_Flag</b></h2>\"))\n",
    "    # Summary information\n",
    "    df_summary_feature = df.groupby(by = target_feature, as_index= False)\\\n",
    "    .agg (\n",
    "        Count = (feature, \"count\"),\n",
    "        Mean = (feature, \"mean\"),\n",
    "        Median = (feature, \"median\"),\n",
    "        Std = (feature, \"std\")\n",
    "    )\n",
    "    df_summary_feature = df_summary_feature.sort_values(by=\"Mean\", ascending=False)    \n",
    "\n",
    "    summary_data = [\n",
    "        (\"Overall Mean\", f\"{df[feature].mean():.2f}\"),\n",
    "        (\"Overall Median\", f\"{df[feature].median()}\"),\n",
    "        (\"Overall Std\", f\"{df[feature].std():.2f}\")\n",
    "    ]\n",
    "    summary_html = \"<ul>\" + \"\".join([f\"<li><b>{k}:</b> {v}</li>\" for k, v in summary_data]) + \"</ul>\"\n",
    "    display(HTML(summary_html))\n",
    "    display(df_summary_feature.style.background_gradient(cmap=cm).set_table_attributes('style=\"width:75%; margin:auto;\"'))\n",
    "\n",
    "    perform_statical_testing(feature=feature, target_feature=target_feature)\n",
    "\n",
    "    # Plot distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.violinplot(x=target_feature, y=feature, data=df, hue=target_feature,\n",
    "                   palette=color(n_colors=len(df[target_feature].unique())), ax=ax)\n",
    "    ax.set_title(f\"Violin plot of {feature} distribution by {target_feature}\", pad=15, weight = \"bold\")\n",
    "    ax.set_xlabel(target_feature, labelpad=10)\n",
    "    ax.set_ylabel(feature, labelpad=10)\n",
    "    plt.grid(axis=\"y\", color=\"gray\", linestyle=\":\", alpha=0.7)\n",
    "    sns.despine(left=False, bottom=False, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in num_features:\n",
    "    plot_numerical_distribution_by_Attrition(feature=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb468d",
   "metadata": {},
   "source": [
    "### Insight Numerical Features by Attrition\n",
    "\n",
    "**1. Customer_Age, Months_on_book**\n",
    "\n",
    "> **Customer\\_Age, Months\\_on\\_book are not a statistically significant factor** <br>\n",
    "> ‚Üí Age, Months_on_book do **not meaningfully differentiate churn behavior**\n",
    "\n",
    "**2. Credit_Limit**\n",
    "\n",
    "> **Credit\\_Limit is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers generally hold **lower credit lines**\n",
    "\n",
    "**3. Avg_Open_To_Buy**\n",
    "\n",
    "> **Avg\\_Open\\_To\\_Buy is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower available credit balance.\n",
    "\n",
    "**4. Total_Trans_Amt**\n",
    "\n",
    "> **Total_Trans_Amt is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower total transicion amount.\n",
    "\n",
    "**5. Total_Trans_Ct** \n",
    "\n",
    "> **Total_Trans_Ct is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower total transicion.\n",
    "\n",
    "**6. Total_Ct_Chng_Q4_Q1**\n",
    "\n",
    "> **Total_Ct_Chng_Q4_Q1 is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower Percentage change in total transaction amount from Q1 to Q4.\n",
    "\n",
    "**7. Total_Amt_Chng_Q4_Q1** \n",
    "\n",
    "> **Total_Amt_Chng_Q4_Q1 is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower rate of change in transaction volume from Q1 to Q4.\n",
    "\n",
    "**8. Avg_Utilization_Ratio**\n",
    "\n",
    "> **Avg_Utilization_Ratio is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower average utilization rate of credit limit.\n",
    "\n",
    "**9. Total_Revolving_Bal**\n",
    "\n",
    "> **Total_Revolving_Bal is statistically and visually associated with churn** <br>\n",
    "> ‚Üí Attrited customers tend to have a lower revolving credit balance (interest payable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a478654a",
   "metadata": {},
   "source": [
    "**Summary of Feature Relationships with Churn**\n",
    "\n",
    "| Feature                  | Type        | Statistical Test Used | Relationship with Attrition | Summary                                                                 |\n",
    "|--------------------------|-------------|------------------------|------------------------------|-------------------------------------------------------------------------|\n",
    "| **Gender**               | Categorical | Chi-Square Test        | ‚úÖ Significant               | Female customers are slightly more likely to churn                     |\n",
    "| **Education_Level**      | Categorical | Chi-Square Test        | ‚ùå Not Significant           | Doctorate holders show higher churn, but overall pattern is weak       |\n",
    "| **Marital_Status**       | Categorical | Chi-Square Test        | ‚ùå Not Significant           | No strong difference between marital groups                            |\n",
    "| **Income_Category**      | Categorical | Chi-Square Test        | ‚úÖ Significant               | $60K‚Äì$80K segment has lowest churn rate                                |\n",
    "| **Card_Category**        | Categorical | Chi-Square Test        | ‚ùå Not Significant           | Card type does not impact churn significantly                          |\n",
    "| **Dependent_count**      | Categorical | Chi-Square Test        | ‚ùå Not Significant           | Weak signal; 3 dependents slightly overrepresented among churners      |\n",
    "| **Months_Inactive_12_mon** | Categorical | Chi-Square Test        | ‚úÖ Significant               | 3‚Äì4 months inactivity strongly linked with higher churn                |\n",
    "| **Contacts_Count_12_mon** | Categorical | Chi-Square Test        | ‚úÖ Significant               | Frequent contact (especially 6/year) associated with high churn        |\n",
    "| **Total_Relationship_Count** | Categorical | Chi-Square Test      | ‚úÖ Significant               | Fewer products (1‚Äì2) linked with higher churn                          |\n",
    "| **Customer_Age**         | Numerical   | Mann‚ÄìWhitney U Test    | ‚ùå Not Significant           | Age does not differ significantly between churned and retained         |\n",
    "| **Months_on_book**       | Numerical   | Mann‚ÄìWhitney U Test    | ‚ùå Not Significant           | Tenure shows no significant churn pattern                              |\n",
    "| **Credit_Limit**         | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers tend to have lower credit limits                     |\n",
    "| **Avg_Open_To_Buy**      | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers have less available credit                           |\n",
    "| **Total_Trans_Amt**      | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers spend less overall                                   |\n",
    "| **Total_Trans_Ct**       | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers have fewer transactions                              |\n",
    "| **Total_Ct_Chng_Q4_Q1**  | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers show smaller increase in transaction count           |\n",
    "| **Total_Amt_Chng_Q4_Q1** | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers show lower growth in transaction volume              |\n",
    "| **Avg_Utilization_Ratio**| Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers have lower utilization rates                         |\n",
    "| **Total_Revolving_Bal**  | Numerical   | Mann‚ÄìWhitney U Test    | ‚úÖ Significant               | Churned customers have lower revolving balances                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33aa267",
   "metadata": {},
   "source": [
    "## Multivariate Analysis\n",
    "### RFM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d66061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create R-F-M\n",
    "df_customer_churn[\"Recency\"] = df_customer_churn[\"Months_on_book\"].max() - df_customer_churn[\"Months_on_book\"] + 1\n",
    "df_customer_churn[\"Frequency\"] = df_customer_churn[\"Total_Trans_Ct\"]\n",
    "df_customer_churn[\"Monetary\"] = df_customer_churn[\"Total_Trans_Amt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn[\"R_Score\"] = pd.qcut(df_customer_churn[\"Recency\"].rank(method=\"first\"), 5, labels=[5, 4, 3, 2, 1])\n",
    "df_customer_churn[\"F_Score\"] = pd.qcut(df_customer_churn[\"Frequency\"].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n",
    "df_customer_churn[\"M_Score\"] = pd.qcut(df_customer_churn[\"Monetary\"].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcedc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn[\"RFM_Segment\"] = df_customer_churn[\"R_Score\"].astype(str) + df_customer_churn[\"F_Score\"].astype(str) + df_customer_churn[\"M_Score\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49435e3c",
   "metadata": {},
   "source": [
    "| Segment                 | Description                                              | RFM Condition         |\n",
    "| ----------------------- | -------------------------------------------------------- | --------------------- |\n",
    "| **Top Customers**       | Purchase frequently, recently, and spend a lot           | `R=5, F=5, M=5`       |\n",
    "| **At Risk / Lost**      | Rarely purchase, haven‚Äôt returned, and spend very little | `R=1‚Äì2, F=1‚Äì2, M=1‚Äì2` |\n",
    "| **New but not engaged** | Recently joined but low purchase activity and spending   | `R=5, F=1, M=1`       |\n",
    "| **Potential Loyalists** | Moderate recency, high frequency and high spending       | `R=3‚Äì4, F=4‚Äì5, M=4‚Äì5` |\n",
    "| **Other**               | Customers not fitting the above profiles                 | Anything else         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rfm(row):\n",
    "    r, f, m = int(row[\"R_Score\"]), int(row[\"F_Score\"]), int(row[\"M_Score\"])\n",
    "\n",
    "    if r == 5 and f == 5 and m == 5:\n",
    "        return \"Top Customers\"\n",
    "    elif r in [1, 2] and f in [1, 2] and m in [1, 2]:\n",
    "        return \"At Risk or Lost\"\n",
    "    elif r == 5 and f == 1 and m == 1:\n",
    "        return \"New but not engaged\"\n",
    "    elif r in [3, 4] and f in [4, 5] and m in [4, 5]:\n",
    "        return \"Potential Loyalists\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df_customer_churn[\"RFM_Segment\"] = df_customer_churn.apply(classify_rfm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b318abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rfm = (\n",
    "    df_customer_churn.groupby(\"RFM_Segment\").agg({\n",
    "        \"Recency\": [\"mean\", \"min\", \"max\"],\n",
    "        \"Frequency\": [\"mean\", \"min\", \"max\"],\n",
    "        \"Monetary\": [\"mean\", \"min\", \"max\"],\n",
    "        \"CLIENTNUM\": \"count\"\n",
    "    })\n",
    "    .sort_values((\"Monetary\", \"mean\"), ascending=False)\n",
    "    .style\n",
    "    .set_caption(\"RFM Summary by Segment\")\n",
    "    .format(precision=0)\n",
    "    .set_table_styles([\n",
    "        {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        {\"selector\": \"caption\", \"props\": [(\"caption-side\", \"top\"), (\"font-size\", \"16px\"), (\"font-weight\", \"bold\")]}\n",
    "    ])\n",
    "    .set_properties(**{\n",
    "        \"text-align\": \"center\",\n",
    "        \"font-size\": \"12px\"\n",
    "    })\n",
    "    .background_gradient(subset=[(\"Recency\", \"mean\"), (\"Frequency\", \"mean\"), (\"Monetary\", \"mean\")], cmap=\"Blues\")\n",
    ")\n",
    "summary_rfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn = df_customer_churn.astype({\n",
    "    \"R_Score\": \"int8\",\n",
    "    \"F_Score\": \"int8\",\n",
    "    \"M_Score\": \"int8\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc75ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import squarify\n",
    "\n",
    "rfm_summarised = df_customer_churn.groupby (by = \"RFM_Segment\", as_index = False)\\\n",
    "                        .agg (\n",
    "                            customersCount = (\"CLIENTNUM\", \"nunique\"),\n",
    "                            total_R = (\"R_Score\", \"sum\"),\n",
    "                            total_F = (\"F_Score\", \"sum\"),\n",
    "                            total_M = (\"M_Score\", \"sum\")\n",
    "                        )\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "squarify.plot(\n",
    "    rfm_summarised[\"customersCount\"].to_list(),\n",
    "    label = rfm_summarised[\"RFM_Segment\"] + \"\\n\" + rfm_summarised[\"customersCount\"].astype(str),\n",
    "    color = color(n_colors=5)\n",
    ")\n",
    "plt.title (\"RFM By Customers Count\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "rfm_summarised = rfm_summarised.sort_values(by=\"total_M\",ascending=False)\n",
    "rfm_summarised[\"cumpercentage\"] = rfm_summarised[\"total_M\"].cumsum()/rfm_summarised[\"total_M\"].sum()*100\n",
    "fig, ax = plt.subplots(figsize = (20, 8))\n",
    "ax.bar(rfm_summarised[\"RFM_Segment\"], rfm_summarised[\"total_M\"], color=\"C0\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(rfm_summarised[\"RFM_Segment\"], rfm_summarised[\"cumpercentage\"], color=\"C1\", marker=\"*\", ms=7)\n",
    "ax2.yaxis.set_major_formatter(PercentFormatter())\n",
    "ax.tick_params(axis=\"y\", colors=\"C0\")\n",
    "ax2.tick_params(axis=\"y\", colors=\"C1\")\n",
    "plt.grid(color = \"green\", linestyle = \"--\", linewidth = 0.5)\n",
    "plt.title (\"Pareto Chart By Customers Segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b95e37",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "| Segment                 | % of Customers | Key Behavior Insights                            | \n",
    "| ----------------------- | -------------- | ------------------------------------------------ |\n",
    "| **Top Customers**       | **2%**         | Most recent, frequent, and highest spenders      |\n",
    "| **Potential Loyalists** | **12%**        | Active with good frequency/spending              |\n",
    "| **Other**               | **68%**        | Average recency, frequency, and spend            |\n",
    "| **At Risk / Lost**      | **13%**        | Previously active, now disengaged (long recency) |\n",
    "| **New, Not Engaged**    | **5%**         | Just joined, low activity & spend                |\n",
    "\n",
    "**Pareto Insight**\n",
    "\n",
    "* **Top 2 groups (\"Top Customers\" + \"Potential Loyalists\") = only 14% of users**\n",
    "* But contribute **nearly 80% of revenue**\n",
    "* ‚Üí Focus efforts on **high-value groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_percent_plot(cat=\"RFM_Segment\", df= df_customer_churn, rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8a583",
   "metadata": {},
   "source": [
    "* **RFM segmentation is strongly associated with churn**\n",
    "* **‚ÄúAt Risk or Lost‚Äù** group needs **recovery strategies**\n",
    "* **‚ÄúTop‚Äù and ‚ÄúPotential Loyalists‚Äù** show strong retention potential\n",
    "* RFM segments are useful **predictors for churn modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68f7c8",
   "metadata": {},
   "source": [
    "### Business Insight Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a66ffa",
   "metadata": {},
   "source": [
    "#### Analyzing the Relationship Between Income and Trading Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5872b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn_bussiness = df_customer_churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e831ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_order = [\"Less than $40K\", \"$40K - $60K\", \"$60K - $80K\", \"$80K - $120K\", \"$120K +\", \"Unknown\"]\n",
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "# --- Barplot 1 ---\n",
    "plt.subplot(1, 2, 1)\n",
    "ax1 = sns.barplot(data=df_customer_churn_bussiness, x=\"Income_Category\", y=\"Total_Trans_Amt\",\n",
    "                  palette=color(n_colors=2), order=income_order, hue=\"Attrition_Flag\")\n",
    "plt.title(\"Average Total Transaction Amount by Income Category\", weight = \"bold\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend().remove()\n",
    "\n",
    "# --- Barplot 2 ---\n",
    "plt.subplot(1, 2, 2)\n",
    "ax2 = sns.barplot(data=df_customer_churn_bussiness, x=\"Income_Category\", y=\"Total_Trans_Ct\", \n",
    "                  palette=color(n_colors=2), order=income_order, hue=\"Attrition_Flag\")\n",
    "plt.title(\"Average Transaction Count by Income Category\", weight = \"bold\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# for container in ax2.containers:\n",
    "#     ax2.bar_label(container, fmt='%.0f', label_type=\"edge\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae95241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg_Open_To_Buy/Credit Limit  theo Income_Category\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(data=df_customer_churn_bussiness, x=\"Income_Category\", y=\"Avg_Open_To_Buy\",\n",
    "                palette=color(n_colors=2), order=income_order, hue=\"Attrition_Flag\")\n",
    "plt.title(\"Distribution of Available Credit by Income Category\", weight = \"bold\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=df_customer_churn_bussiness, x=\"Income_Category\", y=\"Credit_Limit\", order=income_order, palette=color(n_colors=2), hue=\"Attrition_Flag\")\n",
    "plt.title(\"Credit Limit by Income Category\", weight = \"bold\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df_customer_churn_bussiness, x=\"Income_Category\", y=\"Avg_Utilization_Ratio\", order=income_order,  palette=color(n_colors=2), hue=\"Attrition_Flag\")\n",
    "plt.title(\"Avg Utilization Ratio by Income Category\", weight = \"bold\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5933d1",
   "metadata": {},
   "source": [
    "**1. Average Transactions by Income & Customer Status**\n",
    "\n",
    "**Insight:**\n",
    "\n",
    "* **Existing Customers** consistently show higher average transaction amounts and counts across all income groups.\n",
    "* In the `$80K‚Äì$120K` income group, **Attrited Customers** exhibit the highest transaction levels among their peers ‚Äî indicating this may be a **high-value segment that was lost**.\n",
    "\n",
    "**2. Distribution of `Avg_Open_To_Buy` by Income & Churn Status**\n",
    "\n",
    "**Insight:**\n",
    "\n",
    "* **Existing Customers** tend to have significantly **more available credit left** (`Avg_Open_To_Buy`) across all income tiers.\n",
    "* Most **Attrited Customers have low remaining credit**, which may indicate that their cards were either maxed out or rarely used.\n",
    "\n",
    "\n",
    "**3. Credit Limit & Utilization by Income & Churn Status**\n",
    "\n",
    "**Insight:**\n",
    "\n",
    "* **Credit Limit increases clearly with income**, as expected.\n",
    "* However, **Attrited Customers consistently show higher Utilization Ratios** ‚Äî particularly in income groups below `$60K`, where usage often approaches full limit.\n",
    "* This pattern suggests higher financial pressure among churned customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb037003",
   "metadata": {},
   "source": [
    "#### Transaction Analysis by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7280f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Transaction Amount by Customer Age\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(data=df_customer_churn_bussiness, x=\"Customer_Age\", y=\"Total_Trans_Amt\",\n",
    "             hue=\"Attrition_Flag\", palette=color(n_colors=2), ci=None, linewidth=2, alpha=0.9)\n",
    "plt.title(\"Total Transaction Amount by Customer Age\", weight = \"bold\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Transaction by Customer Age\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.lineplot(data=df_customer_churn_bussiness, x=\"Customer_Age\", y=\"Total_Trans_Ct\",\n",
    "             hue=\"Attrition_Flag\", palette=color(n_colors=2), ci=None, linewidth=2, alpha=0.9)\n",
    "plt.title(\"Total Transaction by Customer Age\", weight = \"bold\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_age(age):\n",
    "    if age < 30:\n",
    "        return \"<30\"\n",
    "    elif 30 <= age <= 45:\n",
    "        return \"30‚Äì45\"\n",
    "    elif 46 <= age <= 60:\n",
    "        return \"46‚Äì60\"\n",
    "    else:\n",
    "        return \">60\"\n",
    "\n",
    "cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "\n",
    "df_customer_churn_bussiness[\"Age_Group\"] = df_customer_churn_bussiness[\"Customer_Age\"].apply(categorize_age)\n",
    "\n",
    "age_churn = df_customer_churn_bussiness.groupby(\"Age_Group\")[\"Attrition_Flag\"].value_counts(normalize=True).unstack() * 100\n",
    "\n",
    "ax = age_churn.plot(kind=\"bar\", stacked=True, figsize=(8, 5), cmap=cmap)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%1.2f%%', label_type=\"center\", weight=\"bold\", fontsize=10)\n",
    "plt.title(\"Churn Rate by Age Group\", weight = \"bold\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.legend(title=\"Attrition_Flag\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09076898",
   "metadata": {},
   "source": [
    "**Customer Behavior by Age ‚Äì Business Insights**\n",
    "\n",
    "**1. Total Transaction Amount and Count by Age**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "* **Existing Customers** consistently perform more transactions (both in count and value) than **Attrited Customers**.\n",
    "* Transaction activity **peaks around age 30‚Äì40** and steadily declines after age 60.\n",
    "* For Attrited Customers, spending behavior is **lower overall and declines faster with age**.\n",
    "\n",
    "**2. Churn Rate by Age Group**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "| Age Group | Attrited (%) | Existing (%) |\n",
    "| --------- | ------------ | ------------ |\n",
    "| `<30`     | **8.72%**    | 91.28%       |\n",
    "| `30‚Äì45`   | 15.92%       | 84.08%       |\n",
    "| `46‚Äì60`   | **16.62%**   | 83.38%       |\n",
    "| `>60`     | 14.32%       | 85.68%       |\n",
    "\n",
    "* **Customers under 30** have the **lowest churn rate**, though they transact less.\n",
    "* The **46‚Äì60 segment has the highest churn rate**, suggesting unmet needs or declining satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdfb40",
   "metadata": {},
   "source": [
    "#### Consumer Behavior by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_Trans_Amt and Total_Trans_Ct by Gender\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=df_customer_churn_bussiness, x=\"Gender\", y=\"Total_Trans_Amt\",\n",
    "            estimator=\"mean\", palette=color(n_colors=2),  hue=\"Attrition_Flag\")\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.title(\"Average Total Transaction Amount by Gender\", weight = \"bold\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(data=df_customer_churn_bussiness, x=\"Gender\", y=\"Total_Trans_Ct\",\n",
    "            estimator=\"mean\", palette=color(n_colors=2),  hue=\"Attrition_Flag\")\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.title(\"Average Transaction Count by Gender\", weight = \"bold\")\n",
    "plt.legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg_Utilization_Ratio and Months_Inactive_12_mon between Male v√† Female\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.violinplot(data=df_customer_churn, x=\"Gender\", y=\"Avg_Utilization_Ratio\",\n",
    "               palette=color(n_colors=2), hue=\"Attrition_Flag\")\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.title(\"Credit Utilization Ratio by Gender\", weight = \"bold\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.violinplot(data=df_customer_churn, x=\"Gender\", y=\"Months_Inactive_12_mon\",\n",
    "               palette=color(n_colors=2), hue=\"Attrition_Flag\")\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.title(\"Months Inactive in Last 12 Months by Gender\", weight = \"bold\")\n",
    "plt.legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f1cda",
   "metadata": {},
   "source": [
    "**1. Average Transactions by Gender (`Total_Trans_Amt`, `Total_Trans_Ct`)**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "* **Existing Customers** have significantly higher transaction amounts and counts than **Attrited Customers**, for both males and females.\n",
    "* Among **Attrited Customers**, **males have higher average transaction amounts** than females.\n",
    "* Transaction count is fairly similar between genders in the attrited group, but **female Existing Customers perform more transactions** than males.\n",
    "\n",
    "**2. Distribution of `Avg_Utilization_Ratio` and `Months_Inactive_12_mon` by Gender**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "* For `Avg_Utilization_Ratio`:\n",
    "\n",
    "  * Most customers have low utilization ratios, concentrated near zero.\n",
    "  * **Attrited Customers** show a wider spread toward high utilization, especially among females.\n",
    "  * No major difference is observed between genders in the **Existing Customer** group.\n",
    "\n",
    "* For `Months_Inactive_12_mon`:\n",
    "\n",
    "  * Both genders show similar distributions.\n",
    "  * Most customers had 2‚Äì3 months of inactivity in the past year.\n",
    "  * **Attrited Customers** exhibit more variation, but no clear gender-specific trend is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e281ba",
   "metadata": {},
   "source": [
    "#### Credit Utilization Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599987ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_customer_churn_bussiness,\n",
    "    x=\"Avg_Utilization_Ratio\",\n",
    "    y=\"Total_Trans_Amt\",\n",
    "    hue=\"Attrition_Flag\",\n",
    "    alpha=0.6,\n",
    "    palette=color(n_colors=2)\n",
    ")\n",
    "plt.title(\"Utilization Ratio vs. Total Transaction Amount\")\n",
    "plt.xlabel(\"Avg Utilization Ratio\")\n",
    "plt.ylabel(\"Total Transaction Amount\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_customer_churn,\n",
    "    x=\"Credit_Limit\",\n",
    "    y=\"Avg_Open_To_Buy\",\n",
    "    hue=\"Attrition_Flag\",\n",
    "    alpha=0.6,\n",
    "    palette=color(n_colors=2)\n",
    ")\n",
    "plt.title(\"Open To Buy vs. Credit Limit\")\n",
    "plt.xlabel(\"Credit Limit\")\n",
    "plt.ylabel(\"Avg Open To Buy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn_bussiness[\"OpenToLimitRatio\"] = df_customer_churn_bussiness[\"Avg_Open_To_Buy\"] / df_customer_churn_bussiness[\"Credit_Limit\"]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_customer_churn_bussiness[\"OpenToLimitRatio\"], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Avg Open to Buy / Credit Limit\")\n",
    "plt.xlabel(\"Open To Buy Ratio\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad1945",
   "metadata": {},
   "source": [
    "**1. Chart: `Avg_Utilization_Ratio` vs. `Total_Trans_Amt`**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "* The data forms several horizontal \"bands\" ‚Äî indicating common spending levels (e.g., 2,500 / 5,000 / 10,000...).\n",
    "* Most data points are concentrated at low `Avg_Utilization_Ratio` values (below 0.4), even when `Total_Trans_Amt` is high.\n",
    "* There is no clear linear relationship between credit utilization and spending amount.\n",
    "* **Existing Customers** show a wider spread along both axes.\n",
    "\n",
    "**2. Chart: `Avg_Open_To_Buy` vs. `Credit_Limit`**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "* The points lie almost perfectly on a diagonal ‚Äî indicating a near-linear relationship between `Credit_Limit` and `Avg_Open_To_Buy`.\n",
    "* This is expected because:\n",
    "  `Avg_Open_To_Buy ‚âà Credit_Limit - Avg_Revolving_Bal`.\n",
    "* The distribution appears similar across both **Attrited** and **Existing** customer groups.\n",
    "\n",
    "**3. Chart: Distribution of `Avg_Open_To_Buy / Credit_Limit`**\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "* The distribution is heavily right-skewed ‚Äî the majority of customers have an **open-to-buy ratio > 0.8**, indicating a large portion of their credit limit remains unused.\n",
    "* The peak occurs close to 1.0, confirming that most customers are using very little of their available credit.\n",
    "* A smaller subset has ratios below 0.4, meaning they are utilizing most of their limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0564f4f",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Data Preprocessing</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Data Preprocessing\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66d379",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66378dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn[\"Utilization_Ratio_Per_Trans\"] = df_customer_churn[\"Avg_Utilization_Ratio\"] / (df_customer_churn[\"Total_Trans_Ct\"] + 1)\n",
    "df_customer_churn[\"Credit_Usage_Efficiency\"] = df_customer_churn[\"Total_Trans_Amt\"] / (df_customer_churn[\"Credit_Limit\"] + 1)\n",
    "df_customer_churn[\"Trans_Change_Rate\"] = df_customer_churn[\"Total_Ct_Chng_Q4_Q1\"] / (df_customer_churn[\"Total_Trans_Ct\"] + 1)\n",
    "df_customer_churn[\"Age_To_Months_Ratio\"] = df_customer_churn[\"Customer_Age\"] / (df_customer_churn[\"Months_on_book\"] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad92ed",
   "metadata": {},
   "source": [
    "`Utilization_Ratio_Per_Trans`\n",
    "\n",
    "* Measures the **average utilization ratio per transaction**.\n",
    "* Helps distinguish customers who **make fewer but larger transactions** (potentially high risk) from those who **spend smaller amounts more frequently**.\n",
    "\n",
    "`Credit_Usage_Efficiency`\n",
    "\n",
    "* Indicates how efficiently the customer **converts their credit limit into actual transaction amount**.\n",
    "* High values may reflect good utilization ‚Äî or possibly overextension.\n",
    "\n",
    "`Open_To_Buy_Ratio`\n",
    "\n",
    "* Represents the **remaining credit capacity**.\n",
    "* High ratio ‚Üí customer still has large available credit.\n",
    "* Low ratio ‚Üí customer is utilizing most of their limit, potentially risky.\n",
    "\n",
    "`Trans_Change_Rate`\n",
    "\n",
    "* Measures the **rate of transaction count change between Q4 and Q1** relative to total transactions.\n",
    "* A high value suggests **behavioral shifts**, which could be early signs of churn or instability.\n",
    "\n",
    "`Age_To_Months_Ratio`\n",
    "\n",
    "* Estimates the **relative age at account creation**.\n",
    "* Younger customers with long tenure may indicate **higher loyalty**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efe3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feature_drop = [\"Recency\", \"Frequency\", \"Monetary\", \"R_Score\", \"F_Score\", \"M_Score\", \"CLIENTNUM\"]\n",
    "df_customer_churn.drop(columns=list_feature_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_customer_churn.corr(numeric_only=True)\n",
    "# one_like can build a matrix of boolean(True, False) with the same shape as our data\n",
    "ones_corr = np.ones_like(corr_matrix, dtype=bool)\n",
    "mask = np.triu(ones_corr)\n",
    "adjusted_mask = mask[1:, :-1]\n",
    "adjusted_cereal_corr = corr_matrix.iloc[1:, :-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 9))\n",
    "# That method uses HUSL colors, so you need hue, saturation, and lightness. \n",
    "# I used hsluv.org to select the colors of this chart.\n",
    "cmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data=adjusted_cereal_corr, mask=adjusted_mask,\n",
    "            annot=True, fmt=\".2f\", cmap=cmap,\n",
    "            vmin=-1, vmax=1, linecolor=\"white\", linewidths=0.5)\n",
    "\n",
    "title = \"CORRELATION MATRIX COMPOSITION\\n\"\n",
    "ax.set_title(title, loc=\"left\", fontsize=18, weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = df_customer_churn[num_features].columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(df_customer_churn[num_features].values, i)\n",
    "                   for i in range(len(df_customer_churn[num_features].columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bb777",
   "metadata": {},
   "source": [
    "**VIF Analysis ‚Äì Detecting Multicollinearity in Numerical Features**\n",
    "\n",
    "**What is VIF?**\n",
    "\n",
    "* **VIF (Variance Inflation Factor)** measures how much a feature is **linearly explained by other features**.\n",
    "* **Higher VIF** ‚Üí stronger multicollinearity ‚Üí coefficient becomes unstable in linear models.\n",
    "\n",
    "| VIF Value   | Interpretation                       |\n",
    "| ----------- | ------------------------------------ |\n",
    "| **1‚Äì5**     | Low multicollinearity (acceptable)   |\n",
    "| **5‚Äì10**    | Moderate correlation (check closely) |\n",
    "| **> 10**    | **High multicollinearity** (problem) |\n",
    "| **inf (‚àû)** | Perfect linear relationship ‚Üí drop!  |\n",
    "\n",
    "**Key Findings from VIF Table**\n",
    "\n",
    "| Feature                    | VIF Score | Interpretation                                                                |\n",
    "| -------------------------- | --------- | ----------------------------------------------------------------------------- |\n",
    "| **Credit\\_Limit**          | ‚àû         | Perfect multicollinearity ‚Äî likely caused by `Avg_Open_To_Buy` being derived. |\n",
    "| **Avg\\_Open\\_To\\_Buy**     | ‚àû         | Strongly collinear with `Credit_Limit` (‚Üí recommend **drop 1 of them**)       |\n",
    "| **Customer\\_Age**          | 219.7     | Very high collinearity with `Months_on_book` (r = 0.79)                       |\n",
    "| **Months\\_on\\_book**       | 132.2     | Same issue ‚Äî should keep only **one** of the pair                             |\n",
    "| **Total\\_Trans\\_Ct**       | 56.6      | Strong correlation with `Total_Trans_Amt` (r = 0.81) ‚Äî consider dropping one  |\n",
    "| **Age\\_To\\_Months\\_Ratio** | 59.3      | Derived from age/months ‚Üí high VIF is expected                                |\n",
    "\n",
    "**Features with Multicollinearity Risk (VIF > 10)**\n",
    "\n",
    "* `Credit_Limit`, `Avg_Open_To_Buy` ‚Üí **Perfect correlation**\n",
    "* `Customer_Age`, `Months_on_book` ‚Üí **Very high redundancy**\n",
    "* `Total_Trans_Ct`, `Total_Trans_Amt` ‚Üí strong positive linear dependency\n",
    "* `Age_To_Months_Ratio` ‚Üí engineered feature, already dependent\n",
    "\n",
    "**Handling Multicollinearity in Feature Set**\n",
    "\n",
    "Although several features exhibit **high multicollinearity** (e.g., high VIF scores or perfect correlations),\n",
    "we will **not drop any of them** at this stage.\n",
    "\n",
    "> This decision is based on the fact that **multicollinearity primarily affects linear models** (e.g., Logistic Regression),\n",
    "> whereas **non-linear models** (e.g., Decision Trees, Random Forest, XGBoost) are **not sensitive** to collinear features.\n",
    "\n",
    "Furthermore:\n",
    "\n",
    "* Tree-based models **naturally handle redundant features** by selecting only the most informative splits.\n",
    "* Removing features too early might lead to **loss of potentially useful signals** for churn prediction.\n",
    "\n",
    "üëâ **Action**: We will retain all numerical features for now and rely on model-specific mechanisms (e.g., regularization or feature importance) to handle redundancy if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfbd3ee",
   "metadata": {},
   "source": [
    "## Handling Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd91b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_new_features = [\"Utilization_Ratio_Per_Trans\", \"Credit_Usage_Efficiency\", \"Trans_Change_Rate\", \"Age_To_Months_Ratio\"]\n",
    "num_features.extend(list_new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_feature, skew_df = check_skewness(data=df_customer_churn, numerical_features=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efb21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def handle_skewed_features(\n",
    "    df,\n",
    "    zero_threshold=0.9,\n",
    "    skew_threshold=0.5,\n",
    "    num_features=None,\n",
    "    exclude_cols=None    \n",
    "):\n",
    "    \"\"\"\n",
    "    Handle skewed numerical features by applying appropriate transformations.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame\n",
    "    - zero_threshold: float (default=0.9)\n",
    "    - skew_threshold: float (default=0.5)\n",
    "    - num_features: list of numerical columns to consider\n",
    "    - exclude_cols: list of columns to skip entirely\n",
    "\n",
    "    Returns:\n",
    "    - df: transformed DataFrame\n",
    "    - transformed_cols: list of new feature names\n",
    "    - high_zero_cols: list of sparse features (> zero_threshold)\n",
    "    - skewed_cols: list of auto‚Äëdetected skewed features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if num_features is None:\n",
    "        raise ValueError(\"`num_features` must be provided\")\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "\n",
    "    # 1) pick the numeric cols to scan\n",
    "    numerical_cols = [c for c in num_features if c not in exclude_cols]\n",
    "\n",
    "    # 2) detect ultra‚Äësparse\n",
    "    zero_ratios = (df[numerical_cols] == 0).sum() / len(df)\n",
    "    high_zero_cols = zero_ratios[zero_ratios > zero_threshold].index.tolist()\n",
    "\n",
    "    # 3) compute skew\n",
    "    skew_vals = df[numerical_cols].apply(lambda s: skew(s.dropna()))\n",
    "    auto_skewed = skew_vals[abs(skew_vals) > skew_threshold].index.tolist()\n",
    "\n",
    "    # 4) union these with your forced list\n",
    "    to_transform = list(set(auto_skewed))\n",
    "\n",
    "    transformed_cols = []\n",
    "    dropped_cols     = []\n",
    "\n",
    "    for col in to_transform:\n",
    "        # if it's sparse ‚Üí binary+log\n",
    "        if col in high_zero_cols:\n",
    "            df[f\"Has_{col}\"] = (df[col] > 0).astype(int)\n",
    "            df[f\"Log_{col}\"] = df[col].map(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "            transformed_cols += [f\"Has_{col}\", f\"Log_{col}\"]\n",
    "            dropped_cols.append(col)\n",
    "        # if it's discrete small‚Äëcardinality, skip transform but keep\n",
    "        elif df[col].nunique() <= 5:\n",
    "            # do nothing (we still keep raw col in df)\n",
    "            continue\n",
    "        # otherwise apply Yeo‚ÄëJohnson\n",
    "        else:\n",
    "            pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "            arr = df[[col]].values  # shape (n,1)\n",
    "            df[f\"PT_{col}\"] = pt.fit_transform(arr)\n",
    "            transformed_cols.append(f\"PT_{col}\")\n",
    "            dropped_cols.append(col)\n",
    "\n",
    "    # drop originals for any column we did transform\n",
    "    df.drop(columns=dropped_cols, inplace=True)\n",
    "\n",
    "    return df, transformed_cols, high_zero_cols, auto_skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e06cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df, transformed_columns, sparse_columns, skewed_columns = handle_skewed_features(df=df_customer_churn, \n",
    "                                                                                           num_features=skew_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed633c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feature_skewed = processed_df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "skew_feature, skew_df = check_skewness(data=processed_df, numerical_features=list_feature_skewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c896eea",
   "metadata": {},
   "source": [
    "**Insight** <br>\n",
    "**Observations from the Skewness Table (`processed_df`):**\n",
    "\n",
    "**Approximately Symmetric**: <br>\n",
    "Several features, such as: <br>\n",
    "  * `PT_Utilization_Ratio_Per_Trans`, `PT_Trans_Change_Rate`, `PT_Avg_Utilization_Ratio`, `PT_Credit_Usage_Efficiency`, `PT_Age_To_Months_Ratio`, `PT_Credit_Limit`, `PT_Total_Amt_Chng_Q4_Q1`, `PT_Total_Ct_Chng_Q4_Q1`, `PT_Avg_Open_To_Buy` and `PT_Total_Trans_Amt` show skewness close to `0`.\n",
    "  * This indicates that **Yeo-Johnson transformation was effective** for these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02890e69",
   "metadata": {},
   "source": [
    "## Re-Checking Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ab30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_outlier(list_feature=list_feature_skewed, df=processed_df, dataset_name=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e41c9c",
   "metadata": {},
   "source": [
    "## Create Test Set\n",
    "\n",
    "üî¥ Suppose you chatted with experts who told you that the **Total_Trans_Amt** is a very important attribute to predict **Attrition_Flag**. <br>\n",
    "üî¥ We may want to ensure that the test set is representative of the various categories of total trans amount in the whole dataset. Since the Total_Trans_Amt is a continuous numerical attribute, we first need to create an score category attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_churn[\"Attrition_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_Gender = LabelEncoder()\n",
    "processed_df[\"Gender\"] = le_Gender.fit_transform(processed_df[\"Gender\"])\n",
    "\n",
    "manual_map = {\n",
    "    \"Attrited Customer\": 1,\n",
    "    \"Existing Customer\": 0\n",
    "}\n",
    "\n",
    "processed_df[\"Attrition_Flag\"] = processed_df[\"Attrition_Flag\"].map(manual_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df[\"PT_Total_Trans_Amt_Cat\"] = pd.qcut(processed_df[\"PT_Total_Trans_Amt\"],\n",
    "                                              q=4,\n",
    "                                              labels=[1, 2, 3, 4])\n",
    "\n",
    "sns.histplot(data=processed_df[\"PT_Total_Trans_Amt_Cat\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c51e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(processed_df, processed_df[\"PT_Total_Trans_Amt_Cat\"]):\n",
    "    start_train_set = processed_df.iloc[train_index]\n",
    "    start_test_set = processed_df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aeeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we should remove the PT_Total_Trans_Amt_Cat attribute so the data is back to its original state:\n",
    "for set_ in (start_train_set, start_test_set): \n",
    "    set_.drop(\"PT_Total_Trans_Amt_Cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab985c31",
   "metadata": {},
   "source": [
    "## Scale and Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58015290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Churn_new = start_train_set.drop(\"Attrition_Flag\", axis=1)\n",
    "df_Churn_label = start_train_set[\"Attrition_Flag\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Churn_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feature_num_robust = [\"Customer_Age\",\"Months_on_book\", \"Total_Trans_Ct\",  \"PT_Age_To_Months_Ratio\", \"PT_Avg_Open_To_Buy\",\n",
    "                           \"PT_Total_Ct_Chng_Q4_Q1\", \"PT_Total_Trans_Amt\", \"PT_Trans_Change_Rate\", \"PT_Total_Amt_Chng_Q4_Q1\"]\n",
    "list_feature_num_stand = [\"Total_Revolving_Bal\", \"PT_Credit_Limit\", \"PT_Credit_Usage_Efficiency\", \"PT_Avg_Utilization_Ratio\",\n",
    "                          \"PT_Utilization_Ratio_Per_Trans\"]\n",
    "list_feature_cat_onehot = [\"Education_Level\", \"Marital_Status\", \"Income_Category\", \"Card_Category\", \"Dependent_count\",\n",
    "                           \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Total_Relationship_Count\", \"RFM_Segment\"]\n",
    "list_feature_cat_keep = [\"Gender\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dead3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no **missing values** in dataset. But we will still handle missing values ‚Äã‚Äãto check the data in the future.\n",
    "num_robust_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "num_stand_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_onehot_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")) # Handling Text and Categorical Attributes\n",
    "])\n",
    "\n",
    "cat_keep_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_robust\", num_robust_transformer, list_feature_num_robust),\n",
    "    (\"num_standard\", num_stand_transformer, list_feature_num_stand),\n",
    "    (\"cat_onehot\", cat_onehot_transformer, list_feature_cat_onehot),\n",
    "    (\"cat_keep\", cat_keep_transformer, list_feature_cat_keep),\n",
    "])\n",
    "\n",
    "preprocessor.fit(df_Churn_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Churn_prepared = preprocessor.transform(df_Churn_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba58373",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feature_prepared = preprocessor.get_feature_names_out().tolist()\n",
    "list_feature_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6d7b0",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Define Metric</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Define Metric\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434e203",
   "metadata": {},
   "source": [
    "| Metric        | Definition                                                  | Meaning in Attrition Context                                          |\n",
    "| ------------- | ----------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| **Recall**    | $\\frac{TP}{TP + FN}$                                        | **Most important** ‚Äì how many true leavers you can catch              |\n",
    "| **Precision** | $\\frac{TP}{TP + FP}$                                        | Among predicted leavers, how many are actually correct                |\n",
    "| **Accuracy**  | $\\frac{TP + TN}{Total}$                                     | Can be misleading with imbalanced data (e.g., <20% attrition)         |\n",
    "| **F1-score**  | $\\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}$ | Balanced trade-off between Precision and Recall                       |\n",
    "| **AUC-ROC**   | Area under ROC Curve                                        | Measures ability to distinguish leavers vs. stayers at all thresholds |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950a8b2",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Comparison Models</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Comparison Models\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SMOTE to handling imbalance data.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(df_Churn_prepared, df_Churn_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbe644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier,\n",
    "AdaBoostClassifier, BaggingClassifier)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "seed = 42\n",
    "max_iter = 50000\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "models = [\n",
    "    LinearSVC(max_iter=max_iter, random_state=42),\n",
    "    SVC(kernel=\"rbf\", random_state=seed),\n",
    "    KNeighborsClassifier(metric = \"minkowski\", p = 2, n_neighbors=5),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(solver=\"liblinear\", max_iter=max_iter, random_state=seed),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=seed),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=seed),\n",
    "    ExtraTreesClassifier(random_state=seed),\n",
    "    AdaBoostClassifier(random_state=seed),\n",
    "    XGBClassifier(n_estimators= 2000, max_depth= 4, eval_metric = \"logloss\",\n",
    "                  random_state=seed, min_child_weight= 2, gamma=0.9,\n",
    "                  subsample=0.8, colsample_bytree=0.8, objective= \"binary:logistic\",\n",
    "                  nthread= -1),\n",
    "    MLPClassifier(max_iter=max_iter, random_state=seed),\n",
    "    GradientBoostingClassifier(random_state=seed),\n",
    "    RidgeClassifier(alpha=1.0, random_state=seed, max_iter=max_iter),\n",
    "    RidgeClassifierCV(alphas=[0.1, 0.5, 1.0], cv=kfold),\n",
    "    CatBoostClassifier(verbose=0, random_seed=seed, allow_writing_files=False),\n",
    "    BaggingClassifier(random_state=seed),\n",
    "    LGBMClassifier(random_state=seed, verbosity=-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baseline_results(models = models, X = X_resampled, y = y_resampled, metric = \"roc_auc\",\n",
    "                              cv = kfold, plot_result = False):\n",
    "    entries = []\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        model_scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "        for fold_idx, score in enumerate(model_scores):\n",
    "            entries.append((model_name, fold_idx, score))\n",
    "        cv_df = pd.DataFrame(entries, columns=[\"model_name\", \"fold_id\", \"roc_auc_score\"])\n",
    "\n",
    "    # Summary\n",
    "    mean = cv_df.groupby(\"model_name\")[\"roc_auc_score\"].mean()\n",
    "    std = cv_df.groupby(\"model_name\")[\"roc_auc_score\"].std()\n",
    "\n",
    "    baseline_result = pd.concat([mean, std], axis=1, ignore_index=True)\n",
    "    baseline_result.columns = [\"Mean\", \"Standard Deviation\"]\n",
    "\n",
    "    # Sort by roc_auc\n",
    "    baseline_result.sort_values(by=[\"Mean\"], ascending=False, inplace=True)   \n",
    "\n",
    "    if plot_result:\n",
    "        plt.figure(figsize=(18, 8))\n",
    "        sns.barplot(x=\"model_name\", y=\"roc_auc_score\", data=cv_df, palette=\"viridis\")\n",
    "        plt.title(\"Base-Line Model ROC AUC using 5-fold cross-validation\", fontsize=14, weight=\"bold\", pad=20)\n",
    "        plt.xlabel(\"Model\")\n",
    "        plt.ylabel(\"roc_auc_score\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return baseline_result\n",
    "    else:\n",
    "        return baseline_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_baseline_results(plot_result = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039210e9",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Hyperparameter tuning</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Hyperparameter tuning\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9156b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_plot(model, X_test, list_feature, type = None):    \n",
    "     # https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137/\n",
    "    if hasattr(X_test, \"toarray\"):\n",
    "        X_test = X_test.toarray()\n",
    "    X_test_sample = pd.DataFrame(X_test, columns=list_feature)\n",
    "    explainer = shap.Explainer(model.predict, X_test_sample)\n",
    "    shap_values = explainer(X_test_sample)\n",
    "    if type ==\"bar\":\n",
    "        shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "        shap_df = pd.DataFrame({\"feature\": X_test_sample.columns, \"importance\": shap_importance})\n",
    "        shap_df = shap_df.sort_values(\"importance\", ascending=False).head(20)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=shap_df[\"importance\"], y=shap_df[\"feature\"], palette=\"viridis\", order=shap_df[\"feature\"])\n",
    "        plt.xlabel(\"mean(|SHAP value|)\")\n",
    "        plt.title(\"SHAP Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_confusionMatrix(estimator, X_val, y_val, figsize):\n",
    "    y_pred_prob = estimator.predict_proba(X_val)[:, 1]  # Probability of positive class\n",
    "    y_pred = estimator.predict(X_val)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, sharey=False, figsize=figsize)\n",
    "    \n",
    "    # Plot 1    \n",
    "    # Calculate ROC\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
    "    rocScore = roc_auc_score(y_val, y_pred_prob)\n",
    "\n",
    "    ax[0, 0].plot(fpr, tpr, label=f\"{estimator.__class__.__name__} (AUC = {rocScore:.2f})\")\n",
    "    ax[0, 0].plot([0, 1], [0, 1], \"b--\")\n",
    "    ax[0, 0].set_xlabel(\"False Positive Rate\")\n",
    "    ax[0, 0].set_ylabel(\"True Positive Rate\")\n",
    "    ax[0, 0].set_title(f\"ROC ({estimator.__class__.__name__})\", weight=\"bold\")\n",
    "    ax[0, 0].legend()\n",
    "\n",
    "    # Plot 2\n",
    "    confusionMatrix = confusion_matrix(y_val, y_pred)\n",
    "    sns.heatmap(confusionMatrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[0, 1])\n",
    "    ax[0, 1].set_title(f\"Confusion Matrix ({estimator.__class__.__name__})\", weight=\"bold\")\n",
    "    ax[0, 1].set_xlabel(\"Prediction\")\n",
    "    ax[0, 1].set_ylabel(\"Actual\")\n",
    "\n",
    "    # plot 3\n",
    "    precision, recall, thresholds_pr = precision_recall_curve(y_val, y_pred_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    ax[1, 0].plot(recall, precision, label=f\"PR Curve (AUC = {pr_auc:.3f})\")\n",
    "    ax[1, 0].set_xlabel(\"Recall\")\n",
    "    ax[1, 0].set_ylabel(\"Precision\")\n",
    "    ax[1, 0].set_title(\"Precision-Recall Curve\", weight=\"bold\")\n",
    "    ax[1, 0].legend()\n",
    "    \n",
    "    ax.flat[-1].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_val, y_train, y_val, figsize = (15, 6), show_shap_plot = False):\n",
    "    print(f\"Evaluating {model.__class__.__name__}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    plot_ROC_confusionMatrix(estimator = model, X_val = X_val, y_val = y_val, figsize = figsize)\n",
    "    if show_shap_plot:\n",
    "        shap_sample = X_val.iloc[:200] if isinstance(X_val, pd.DataFrame) else X_val[:200]\n",
    "        shap_plot(model=model, X_test=shap_sample, list_feature=list_feature_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = start_test_set.drop(\"Attrition_Flag\", axis=1)\n",
    "y_test = start_test_set[\"Attrition_Flag\"].copy()\n",
    "X_test_prepared = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a0c7b",
   "metadata": {},
   "source": [
    "## CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8707841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running optuna.\n",
    "param_cb = {\n",
    " \"iterations\": 687,\n",
    " \"learning_rate\": 0.22278841471925673,\n",
    " \"depth\": 7,\n",
    " \"l2_leaf_reg\": 2.146037400088227,\n",
    " \"border_count\": 54,\n",
    " \"random_strength\": 0.07669797192938685,\n",
    " \"bagging_temperature\": 0.9398972489915723,\n",
    " \"eval_metric\": \"AUC\",\n",
    " \"loss_function\": \"Logloss\",\n",
    " \"verbose\": 0,\n",
    " \"random_seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29029dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cb = CatBoostClassifier(**param_cb)\n",
    "best_model_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model = best_model_cb, X_train=X_resampled, X_val=X_test_prepared,\n",
    "               y_train=y_resampled, y_val=y_test, figsize=(15, 10), show_shap_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d638339",
   "metadata": {},
   "source": [
    "## LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb98e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running optuna.\n",
    "param_lgbm = {\n",
    " \"n_estimators\": 864,\n",
    " \"learning_rate\": 0.061163220617013334,\n",
    " \"num_leaves\": 110,\n",
    " \"max_depth\": 13,\n",
    " \"min_child_samples\": 31,\n",
    " \"subsample\": 0.6463158924558087,\n",
    " \"colsample_bytree\": 0.7909944139467433,\n",
    " \"reg_alpha\": 7.855232280011533e-07,\n",
    " \"reg_lambda\": 0.1044433782968261,\n",
    " \"random_seed\": seed,\n",
    " \"n_jobs\": -1,\n",
    " \"verbosity\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lgbm = LGBMClassifier(**param_lgbm)\n",
    "best_model_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d823bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model = best_model_lgbm, X_train=X_resampled, X_val=X_test_prepared,\n",
    "               y_train=y_resampled, y_val=y_test, figsize=(15, 10), show_shap_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6703cb8",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5383f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running optuna.\n",
    "param_xgb = {\n",
    " \"n_estimators\": 831,\n",
    " \"max_depth\": 12,\n",
    " \"learning_rate\": 0.02583971809059078,\n",
    " \"subsample\": 0.6245033991063241,\n",
    " \"colsample_bytree\": 0.7600912832095267,\n",
    " \"gamma\": 1.8611817476742898,\n",
    " \"reg_alpha\": 0.28438437703658187,\n",
    " \"reg_lambda\": 0.00013468443121609304,\n",
    " \"min_child_weight\": 1,\n",
    " \"random_state\": seed,\n",
    " \"n_jobs\": -1,\n",
    " \"verbosity\": 0,\n",
    " \"use_label_encoder\": False,\n",
    " \"eval_metric\": \"auc\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d98e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_xgb = XGBClassifier(**param_xgb)\n",
    "best_model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5cf11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model = best_model_xgb, X_train=X_resampled, X_val=X_test_prepared,\n",
    "               y_train=y_resampled, y_val=y_test, figsize=(15, 10), show_shap_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd6f92",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Conclusion</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Conclusion\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bcec1",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"catboost\", best_model_cb),\n",
    "        (\"xgb\", best_model_xgb),\n",
    "        (\"lgbm\", best_model_lgbm)\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(\n",
    "    voting_clf_soft,\n",
    "    X=X_resampled,\n",
    "    y=y_resampled,\n",
    "    cv=kfold,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"Cross-validated ROC AUC (mean ¬± std): {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3365cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model = voting_clf_soft, X_train=X_resampled, X_val=X_test_prepared,\n",
    "               y_train=y_resampled, y_val=y_test, figsize=(15, 10), show_shap_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb719c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sample = X_test_prepared.iloc[:200] if isinstance(X_test_prepared, pd.DataFrame) else X_test_prepared[:200]\n",
    "shap_plot(model=voting_clf_soft, X_test=shap_sample, list_feature=list_feature_prepared, type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74054e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot(model=voting_clf_soft, X_test=shap_sample, list_feature=list_feature_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d040d",
   "metadata": {},
   "source": [
    "**Top 5 Most Influential Features**\n",
    "\n",
    "| Feature                                         | Interpretation                                                                                                                           |\n",
    "| ----------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **num\\_robust\\_\\_Total\\_Trans\\_Ct**             | Transaction count is the **most important factor**. More frequent transactions (red) lead to higher credit score predictions.            |\n",
    "| **num\\_robust\\_\\_PT\\_Total\\_Trans\\_Amt**        | Total transaction amount (proportional). Higher spending indicates stronger financial behavior, contributing positively to credit score. |\n",
    "| **num\\_standard\\_\\_Total\\_Revolving\\_Bal**      | Total revolving balance. High values (red) lead to negative SHAP values ‚Äî indicating potential risk due to high debt levels.             |\n",
    "| **num\\_robust\\_\\_PT\\_Total\\_Ct\\_Chng\\_Q4\\_Q1**  | Change in transaction count between Q4 and Q1. Sudden increases or drops reflect financial volatility and can influence score both ways. |\n",
    "| **num\\_robust\\_\\_PT\\_Total\\_Amt\\_Chng\\_Q4\\_Q1** | Change in transaction amount between quarters. The impact is bidirectional depending on the direction and magnitude of change.           |\n",
    "\n",
    "**Other Notable Features:**\n",
    "\n",
    "| Feature                                    | Interpretation                                                                                                              |\n",
    "| ------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `cat_onehot__Months_Inactive_12_mon_1`     | Customers inactive for 1 month in the past year show strong negative impact (red dots shifting left).                       |\n",
    "| `num_robust__Customer_Age`                 | Age has mild influence. Older customers tend to have positive SHAP values, possibly reflecting more stable credit behavior. |\n",
    "| `num_standard__PT_Credit_Usage_Efficiency` | Efficiency of credit usage ‚Äî higher efficiency (red) contributes positively to credit score.                                |\n",
    "| `cat_keep__Gender`                         | Minimal effect ‚Äî the model doesn‚Äôt significantly differentiate by gender.                                                   |\n",
    "| `num_standard__PT_Credit_Limit`            | Credit limit has minor influence but follows expected direction: higher limit ‚Üí higher predicted score.                     |\n",
    "\n",
    "**General Takeaways:**\n",
    "\n",
    "* **Credit behavior** (transactions, balances, quarter-over-quarter changes) is the **dominant signal** in determining credit score.\n",
    "* Categorical features like one-hot encoded `inactive months` and `relationship count` also provide meaningful patterns.\n",
    "* **Demographics** like gender or marital status play a **less important role**, indicating the model focuses more on **behavioral and financial indicators**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caff228",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "# <span style=\"color:transparent;\">Recommendation</span>\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        Recommendation\n",
    "    </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841f964",
   "metadata": {},
   "source": [
    "**Summary Table ‚Äì SHAP Importance & Statistical Significance**\n",
    "\n",
    "| Feature                        | SHAP Importance | Stat Test Significance | Combined Insight                                                    | Suggested Action                                                    |\n",
    "| ------------------------------ | --------------- | ---------------------- | ------------------------------------------------------------------- | ------------------------------------------------------------------- |\n",
    "| **Total\\_Trans\\_Ct**           | Very High    | ‚úÖ Significant          | Fewer transactions ‚Üí higher churn risk                              | Monitor customers with low activity; send offers to re-engage usage |\n",
    "| **Total\\_Trans\\_Amt**          | Very High    | ‚úÖ Significant          | Lower spending ‚Üí associated with higher churn                       | Encourage spend with personalized promotions                        |\n",
    "| **Total\\_Revolving\\_Bal**      | High         | ‚úÖ Significant          | Low balance may reflect card inactivity ‚Üí churn risk                | Target low-usage customers with usage incentives                    |\n",
    "| **Total\\_Ct\\_Chng\\_Q4\\_Q1**    | Medium       | ‚úÖ Significant          | Smaller increase in transaction count ‚Üí churn-prone                 | Flag drop in transactional patterns; re-engagement campaigns        |\n",
    "| **Total\\_Amt\\_Chng\\_Q4\\_Q1**   | Medium       | ‚úÖ Significant          | Low spending growth over time ‚Üí churn signal                        | Promote positive spending trends through milestone offers           |\n",
    "| **Avg\\_Open\\_To\\_Buy**         | Low          | ‚úÖ Significant          | Less available credit ‚Üí potential disengagement                     | Consider offering alternative card options                          |\n",
    "| **Contacts\\_Count\\_12\\_mon**   | Low          | ‚úÖ Significant          | Frequent contact ‚Üí correlated with churn (possibly dissatisfaction) | Balance communication; avoid overwhelming the customer              |\n",
    "| **Months\\_Inactive\\_12\\_mon**  | Medium       | ‚úÖ Significant          | 3‚Äì4 inactive months ‚Üí strong churn predictor                        | Launch reactivation campaigns for inactive users                    |\n",
    "| **Total\\_Relationship\\_Count** | Medium       | ‚úÖ Significant          | Fewer linked products (1‚Äì2) ‚Üí less loyal customers                  | Cross-sell/upsell to increase engagement and stickiness             |\n",
    "\n",
    "**Overall Observations:**\n",
    "\n",
    "* Strong alignment between **SHAP-based feature importance** and **statistical test results** reinforces trust in model behavior.\n",
    "* Behavioral indicators (transactions, usage changes) dominate both SHAP impact and statistical correlation.\n",
    "* Demographic features like `Gender`, `Marital_Status`, and `Education_Level` show low predictive value, validating the model‚Äôs behavioral focus.\n",
    "\n",
    "**Strategic Recommendations:**\n",
    "\n",
    "| Behavioral Segment              | Key Features                        | Recommended Strategy                                         |\n",
    "| ------------------------------- | ----------------------------------- | ------------------------------------------------------------ |\n",
    "| **Low activity users**          | `Total_Trans_Ct`, `Total_Trans_Amt` | Use cashback or bonus incentives tied to usage thresholds    |\n",
    "| **Declining engagement**        | `*_Chng_Q4_Q1`                      | Early alerts + customer support follow-up                    |\n",
    "| **Limited product holders**     | `Total_Relationship_Count`          | Introduce new product bundles or upgrade options             |\n",
    "| **Inactive users (3‚Äì4 months)** | `Months_Inactive_12_mon`            | Trigger personalized reactivation flows                      |\n",
    "| **Over-contacted customers**    | `Contacts_Count_12_mon`             | Optimize communication frequency and tailor outreach content |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33433680",
   "metadata": {},
   "source": [
    "<!-- Include Google Fonts for a modern font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<div style=\"\n",
    "    border-radius: 15px; \n",
    "    border: 2px solid #003366; \n",
    "    padding: 10px; \n",
    "    background: linear-gradient(135deg, #003366, #336699 30%, #66ccff 70%, #99ccff); \n",
    "    text-align: center; \n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\n",
    "\">\n",
    "    <h1 style=\"\n",
    "        color: #FFFFFF; \n",
    "        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7); \n",
    "        font-weight: bold; \n",
    "        margin-bottom: 5px; \n",
    "        font-size: 28px; \n",
    "        font-family: 'Roboto', sans-serif;\n",
    "        letter-spacing: 1px;\n",
    "    \">\n",
    "        üôè Thanks for Reading! üöÄ\n",
    "    </h1>\n",
    "    <p style=\"color: #ffffff; font-size: 18px; text-align: center;\">\n",
    "        Happy Coding! üôåüòä\n",
    "    </p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
